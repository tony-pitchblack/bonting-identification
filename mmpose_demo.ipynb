{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623168fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animal Pose Estimation Demo with AP-10K HRNet Model\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlretrieve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d02dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install required packages\n",
    "# %pip install mmpose mmcv mmdet opencv-python matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f39d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMPose version: 1.3.2\n"
     ]
    }
   ],
   "source": [
    "# Import MMPose modules\n",
    "try:\n",
    "    from mmpose.apis import init_model, inference_topdown\n",
    "    from mmpose.utils import register_all_modules\n",
    "    from mmdet.apis import init_detector, inference_detector\n",
    "    import mmpose\n",
    "    print(f\"MMPose version: {mmpose.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Please install mmpose and dependencies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3da3310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading configs/hrnet_w48_ap10k_256x256.py...\n",
      "Downloaded configs/hrnet_w48_ap10k_256x256.py\n",
      "Downloading models/hrnet_w48_ap10k_256x256.pth...\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m det_model = \u001b[33m\"\u001b[39m\u001b[33mmodels/yolox_x_8x8_300e_coco.pth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m download_file(CONFIG_URL, pose_config)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpose_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m download_file(DET_CONFIG_URL, det_config)\n\u001b[32m     41\u001b[39m download_file(DET_MODEL_URL, det_model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mdownload_file\u001b[39m\u001b[34m(url, filename)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(filename):\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownloaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/bonting-id/lib/python3.11/urllib/request.py:241\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    226\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    242\u001b[39m     headers = fp.info()\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/bonting-id/lib/python3.11/urllib/request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/bonting-id/lib/python3.11/urllib/request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/bonting-id/lib/python3.11/urllib/request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/bonting-id/lib/python3.11/urllib/request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    562\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/bonting-id/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/bonting-id/lib/python3.11/urllib/request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "# Model configuration\n",
    "CONFIG_URL = (\n",
    "    \"https://raw.githubusercontent.com/open-mmlab/mmpose/main/\"\n",
    "    \"configs/animal_2d_keypoint/topdown_heatmap/ap10k/\"\n",
    "    \"td-hm_hrnet-w48_8xb64-210e_ap10k-256x256.py\"\n",
    ")\n",
    "\n",
    "MODEL_URL = \"https://download.openmmlab.com/mmpose/animal/hrnet/hrnet_w48_ap10k_256x256-0e4a3462_20220830.pth\"\n",
    "\n",
    "# Detection model for animal detection\n",
    "# Detection model for animal detection\n",
    "DET_CONFIG_URL = (\n",
    "    \"https://raw.githubusercontent.com/open-mmlab/mmdetection/main/\"\n",
    "    \"configs/yolox/yolox_x_8x8_300e_coco.py\"\n",
    ")\n",
    "DET_MODEL_URL = \"https://download.openmmlab.com/mmdetection/v2.0/yolox/yolox_x_8x8_300e_coco/yolox_x_8x8_300e_coco_20211126_140254-1ef88d67.pth\"\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "\n",
    "# Download model files\n",
    "def download_file(url, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        urlretrieve(url, filename)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"{filename} already exists\")\n",
    "\n",
    "# Download config and model files\n",
    "pose_config = \"configs/hrnet_w48_ap10k_256x256.py\"\n",
    "pose_model = \"models/hrnet_w48_ap10k_256x256.pth\"\n",
    "det_config = \"configs/yolox_x_8x8_300e_coco.py\"\n",
    "det_model = \"models/yolox_x_8x8_300e_coco.pth\"\n",
    "\n",
    "download_file(CONFIG_URL, pose_config)\n",
    "download_file(MODEL_URL, pose_model)\n",
    "download_file(DET_CONFIG_URL, det_config)\n",
    "download_file(DET_MODEL_URL, det_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "print(\"Initializing models...\")\n",
    "register_all_modules()\n",
    "\n",
    "# Initialize detection model\n",
    "det_model = init_detector(det_config, det_model, device='cpu')\n",
    "\n",
    "# Initialize pose estimation model \n",
    "pose_model = init_model(pose_config, pose_model, device='cpu')\n",
    "\n",
    "print(\"Models initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43f721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process the cow image\n",
    "COW_IMG = 'data/bonting-identification/samples/ear-tags/detection/sample_cow_ear_tag_midrange_clear.png'\n",
    "\n",
    "# Check if image exists\n",
    "if not os.path.exists(COW_IMG):\n",
    "    print(f\"Image not found: {COW_IMG}\")\n",
    "    print(\"Please make sure the image path is correct\")\n",
    "    # Create a dummy image for demonstration\n",
    "    import numpy as np\n",
    "    dummy_img = np.ones((256, 256, 3), dtype=np.uint8) * 128\n",
    "    COW_IMG = \"dummy_cow.jpg\"\n",
    "    cv2.imwrite(COW_IMG, dummy_img)\n",
    "    print(f\"Created dummy image: {COW_IMG}\")\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(COW_IMG)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(image_rgb)\n",
    "plt.title(\"Input Cow Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e55e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run animal detection first\n",
    "print(\"Running animal detection...\")\n",
    "det_results = inference_detector(det_model, COW_IMG)\n",
    "\n",
    "# Extract bounding boxes for animals (assuming class 0 is person, but we'll use any detection)\n",
    "# For COCO dataset: cow is class 21\n",
    "bboxes = []\n",
    "if hasattr(det_results, 'pred_instances'):\n",
    "    # MMDetection v3.0+ format\n",
    "    if len(det_results.pred_instances.bboxes) > 0:\n",
    "        bboxes = det_results.pred_instances.bboxes.cpu().numpy()\n",
    "        scores = det_results.pred_instances.scores.cpu().numpy()\n",
    "        # Filter by confidence threshold\n",
    "        valid_idx = scores > 0.3\n",
    "        bboxes = bboxes[valid_idx]\n",
    "else:\n",
    "    # Legacy format\n",
    "    for i, bbox_list in enumerate(det_results):\n",
    "        if len(bbox_list) > 0:\n",
    "            bboxes.extend(bbox_list[bbox_list[:, 4] > 0.3])\n",
    "\n",
    "if len(bboxes) == 0:\n",
    "    # If no detection, use full image\n",
    "    h, w = image.shape[:2]\n",
    "    bboxes = [[0, 0, w, h, 1.0]]\n",
    "    print(\"No detection found, using full image\")\n",
    "else:\n",
    "    print(f\"Found {len(bboxes)} detection(s)\")\n",
    "\n",
    "print(\"Detection bboxes:\", bboxes[:3])  # Show first 3 boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e10f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pose estimation on detected animals\n",
    "print(\"Running pose estimation...\")\n",
    "pose_results = inference_topdown(pose_model, COW_IMG, bboxes)\n",
    "\n",
    "print(f\"Pose estimation completed! Found {len(pose_results)} result(s)\")\n",
    "\n",
    "# Display results\n",
    "if len(pose_results) > 0:\n",
    "    for i, result in enumerate(pose_results):\n",
    "        print(f\"Result {i}: {len(result.pred_instances.keypoints[0])} keypoints detected\")\n",
    "        print(f\"Keypoint scores: {result.pred_instances.keypoint_scores[0][:5]}...\")  # Show first 5 scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e63d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "def visualize_pose_results(image, pose_results, keypoint_threshold=0.3):\n",
    "    \"\"\"Visualize pose estimation results\"\"\"\n",
    "    # AP-10K keypoint names (17 keypoints)\n",
    "    keypoint_names = [\n",
    "        'Left Eye', 'Right Eye', 'Nose', 'Neck', 'Root of Tail',\n",
    "        'Left Shoulder', 'Left Elbow', 'Left Front Paw', \n",
    "        'Right Shoulder', 'Right Elbow', 'Right Front Paw',\n",
    "        'Left Hip', 'Left Knee', 'Left Back Paw',\n",
    "        'Right Hip', 'Right Knee', 'Right Back Paw'\n",
    "    ]\n",
    "    \n",
    "    # Create a copy of the image for visualization\n",
    "    vis_image = image.copy()\n",
    "    \n",
    "    # Colors for different keypoints (BGR format)\n",
    "    colors = [\n",
    "        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255),\n",
    "        (0, 255, 255), (128, 0, 0), (0, 128, 0), (0, 0, 128), (128, 128, 0),\n",
    "        (128, 0, 128), (0, 128, 128), (255, 128, 0), (255, 0, 128), (128, 255, 0),\n",
    "        (0, 255, 128), (128, 0, 255)\n",
    "    ]\n",
    "    \n",
    "    for result in pose_results:\n",
    "        keypoints = result.pred_instances.keypoints[0]  # Shape: [17, 3] for AP-10K\n",
    "        keypoint_scores = result.pred_instances.keypoint_scores[0]  # Shape: [17]\n",
    "        \n",
    "        # Draw keypoints\n",
    "        for i, ((x, y, v), score) in enumerate(zip(keypoints, keypoint_scores)):\n",
    "            if score > keypoint_threshold and v > 0:  # Only draw visible keypoints with good confidence\n",
    "                color = colors[i % len(colors)]\n",
    "                cv2.circle(vis_image, (int(x), int(y)), 5, color, -1)\n",
    "                cv2.putText(vis_image, f'{i}', (int(x)+5, int(y)-5), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    \n",
    "    return vis_image\n",
    "\n",
    "# Visualize the results\n",
    "if len(pose_results) > 0:\n",
    "    vis_image = visualize_pose_results(image, pose_results)\n",
    "    vis_image_rgb = cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Display side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    ax1.imshow(image_rgb)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(vis_image_rgb)\n",
    "    ax2.set_title(\"Pose Estimation Results (AP-10K 17 keypoints)\")\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print keypoint information\n",
    "    print(\"\\\\nAP-10K Keypoint Mapping:\")\n",
    "    keypoint_names = [\n",
    "        'Left Eye', 'Right Eye', 'Nose', 'Neck', 'Root of Tail',\n",
    "        'Left Shoulder', 'Left Elbow', 'Left Front Paw', \n",
    "        'Right Shoulder', 'Right Elbow', 'Right Front Paw',\n",
    "        'Left Hip', 'Left Knee', 'Left Back Paw',\n",
    "        'Right Hip', 'Right Knee', 'Right Back Paw'\n",
    "    ]\n",
    "    for i, name in enumerate(keypoint_names):\n",
    "        print(f\"{i}: {name}\")\n",
    "else:\n",
    "    print(\"No pose estimation results to visualize\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
