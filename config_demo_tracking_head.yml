# Configuration for roboflow_head_demo.py (image + depth processing)

# Input directories
input_img_dir: "data/3d_cattle_demo/renders/cow_boxed/sliding_clip_120s_v3/case=default/render=image/front_upper/2025-08-04_203708"
input_depth_dir: "data/3d_cattle_demo/renders/cow_boxed/sliding_clip_120s_v3/case=default/render=depth/front_upper/2025-08-05_173119"
scene_config_path: "data/3d_cattle_demo/renders/cow_boxed/sliding_clip_120s_v3/scene_config.json"
# Blender camera object to read parameters from (leave empty to use default)
camera_name: "Camera.front.upper"

# Model selection
# model_framework can be one of: 'roboflow', 'mlflow'
# 'model' is deprecated; kept for backward compatibility when model_framework is omitted
# model_framework: "roboflow"
model_framework: "mlflow"

# Roboflow configuration (used when model_framework == 'roboflow')
model_roboflow:
  model_id: "cow-heads-varied-heoza/2"
  api_url: "http://127.0.0.1:9001"

# MLflow configuration (used when model_framework == 'mlflow')
# When model_type == 'ultralytics' the script will use the 'ultralytics' YOLO package
# Note: tracking URI is sourced from environment variable MLFLOW_TRACKING_URI (.env), not from config
model_mlflow:
  model_name: "yolo12_cow_head"
  model_version: null  # if null, latest version is selected
  model_type: "ultralytics"

# Defaults
defaults:
  font_size: 0.5
  font_scale_multiplier: 1.2  # enlarge drawn text
  confidence_threshold: 0.01
  iou_threshold: 0.01

# Output configuration
output:
  base_dir: "data/bonting-identification/processed_videos/tracking_heads"
  remove_input_prefix: "data/"