{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "SMOKE_TEST = True\n",
        "# SMOKE_TEST = False\n",
        "\n",
        "# Number of models to train - None means all models (ignored in smoke test mode)\n",
        "NUM_MODELS = None\n",
        "\n",
        "# Path to YAML config file containing list of model configs to train\n",
        "CONFIG_LIST = 'notebooks/configs/model_lists/textrecog.yml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore all UserWarnings emitted from any submodule of torch\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=UserWarning,\n",
        "    module=r\"torch.*\"\n",
        ")\n",
        "# Ignore all UserWarnings emitted from any submodule of torch\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=UserWarning,\n",
        "    module=r\"mmcv.*\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Load model configs from YAML file\n",
        "with open(CONFIG_LIST, 'r') as f:\n",
        "    config_paths = yaml.safe_load(f)\n",
        "\n",
        "# Filter out commented lines and empty entries\n",
        "active_configs = [cfg for cfg in config_paths if cfg and not cfg.strip().startswith('#')]\n",
        "\n",
        "# Map model types to checkpoint URLs\n",
        "CHECKPOINT_URLS = {\n",
        "    'abinet_custom': 'https://download.openmmlab.com/mmocr/textrecog/abinet/abinet_20e_st-an_mj/abinet_20e_st-an_mj_20221005_012617-ead8c139.pth',\n",
        "    'abinet-vision_custom': 'https://download.openmmlab.com/mmocr/textrecog/abinet/abinet-vision_20e_st-an_mj/abinet-vision_20e_st-an_mj_20220915_152445-85cfb03d.pth',\n",
        "    'aster_custom': 'https://download.openmmlab.com/mmocr/textrecog/aster/aster_resnet45_6e_st_mj/aster_resnet45_6e_st_mj-cc56eca4.pth',\n",
        "    'crnn_custom': 'https://download.openmmlab.com/mmocr/textrecog/crnn/crnn_mini-vgg_5e_mj/crnn_mini-vgg_5e_mj_20220826_224120-8afbedbb.pth',\n",
        "    'master_custom': 'https://download.openmmlab.com/mmocr/textrecog/master/master_resnet31_12e_st_mj_sa/master_resnet31_12e_st_mj_sa_20220915_152443-f4a5cabc.pth',\n",
        "    'nrtr_custom': 'https://download.openmmlab.com/mmocr/textrecog/nrtr/nrtr_resnet31-1by8-1by4_6e_st_mj/nrtr_resnet31-1by8-1by4_6e_st_mj_20220916_103322-a6a2a123.pth',\n",
        "    'robustscanner_custom': 'https://download.openmmlab.com/mmocr/textrecog/robust_scanner/robustscanner_resnet31_5e_st-sub_mj-sub_sa_real/robustscanner_resnet31_5e_st-sub_mj-sub_sa_real_20220915_152447-7fc35929.pth',\n",
        "    'sar_custom': 'https://download.openmmlab.com/mmocr/textrecog/sar/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real_20220915_171910-04eb4e75.pth',\n",
        "    'satrn_custom': 'https://download.openmmlab.com/mmocr/textrecog/satrn/satrn_shallow_5e_st_mj/satrn_shallow_5e_st_mj_20220915_152443-5fd04a4c.pth',\n",
        "    'svtr_custom': 'https://download.openmmlab.com/mmocr/textrecog/svtr/svtr-base_20e_st_mj/svtr-base_20e_st_mj-ea500101.pth',\n",
        "}\n",
        "\n",
        "# Create mapping from config paths to checkpoint URLs\n",
        "CONFIG_TO_CKPT = {}\n",
        "for config_path in active_configs:\n",
        "    config_path_obj = Path(config_path)\n",
        "    # Extract model type from parent directory name\n",
        "    model_type = config_path_obj.parent.name\n",
        "    if model_type in CHECKPOINT_URLS:\n",
        "        CONFIG_TO_CKPT[config_path] = CHECKPOINT_URLS[model_type]\n",
        "\n",
        "print(f\"Loaded {len(active_configs)} active configs:\")\n",
        "for config in active_configs:\n",
        "    print(f\"  - {config}\")\n",
        "\n",
        "ROOT_CONFIG_FOLDER = 'configs/textrecog'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHneq5LxRT6z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/bonting/bonting-identification\n",
            "07/14 18:33:01 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - Using env variable `MLFLOW_TRACKING_URI` with value of http://localhost:5000 to replace item in config.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmengine/utils/package_utils.py:17: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  _bootstrap._exec(spec, module)\n",
            "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f44cd2cf510>>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/bonting/.local/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
            "    def _clean_thread_parent_frames(\n",
            "\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/14 18:33:04 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m /dev/null \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 | packaged by conda-forge | (main, Jun  4 2025, 14:48:23) [GCC 13.3.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1693254328\n",
            "    GPU 0: NVIDIA GeForce RTX 3090\n",
            "    CUDA_HOME: /opt/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.9, V12.9.86\n",
            "    GCC: gcc (GCC) 15.1.1 20250425\n",
            "    PyTorch: 2.1.0+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu118\n",
            "    OpenCV: 4.10.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1693254328\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "07/14 18:33:04 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "auto_scale_lr = dict(base_batch_size=1536)\n",
            "cegdr_truncated_textrecog_data_root = 'data/CEGD-R_train_test'\n",
            "cegdr_truncated_textrecog_test = dict(\n",
            "    ann_file='textrecog_test_truncated.json',\n",
            "    data_root='data/CEGD-R_train_test',\n",
            "    metainfo=dict(mlflow=dict(name='CEGDR-R_recog_trunc')),\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "cegdr_truncated_textrecog_train = dict(\n",
            "    ann_file='textrecog_train_truncated.json',\n",
            "    data_root='data/CEGD-R_train_test',\n",
            "    metainfo=dict(mlflow=dict(name='CEGDR-R_recog_trunc')),\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "custom_hooks = [\n",
            "    dict(priority='LOW', type='MlflowDatasetHook'),\n",
            "]\n",
            "custom_imports = dict(\n",
            "    allow_failed_imports=False,\n",
            "    imports=[\n",
            "        'mmocr_custom.hooks.mlflow_dataset_hook',\n",
            "    ])\n",
            "cute80_textrecog_data_root = 'data/cute80'\n",
            "cute80_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/cute80',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(_scope_='mmocr', interval=1, type='CheckpointHook'),\n",
            "    logger=dict(_scope_='mmocr', interval=100, type='LoggerHook'),\n",
            "    param_scheduler=dict(_scope_='mmocr', type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(_scope_='mmocr', type='DistSamplerSeedHook'),\n",
            "    sync_buffer=dict(_scope_='mmocr', type='SyncBuffersHook'),\n",
            "    timer=dict(_scope_='mmocr', type='IterTimerHook'),\n",
            "    visualization=dict(\n",
            "        _scope_='mmocr',\n",
            "        draw_gt=False,\n",
            "        draw_pred=False,\n",
            "        enable=False,\n",
            "        interval=1,\n",
            "        show=False,\n",
            "        type='VisualizationHook'))\n",
            "default_scope = 'mmocr'\n",
            "dictionary = dict(\n",
            "    _scope_='mmocr',\n",
            "    dict_file=\n",
            "    '/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/abinet/../../../dicts/lower_english_digits.txt',\n",
            "    same_start_end=True,\n",
            "    type='Dictionary',\n",
            "    with_end=True,\n",
            "    with_padding=False,\n",
            "    with_start=True,\n",
            "    with_unknown=False)\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "icdar2013_857_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test_857.json',\n",
            "    data_root='data/icdar2013',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "icdar2013_textrecog_data_root = 'data/icdar2013'\n",
            "icdar2013_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/icdar2013',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "icdar2013_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/icdar2013',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "icdar2015_1811_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test_1811.json',\n",
            "    data_root='data/icdar2015',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "icdar2015_textrecog_data_root = 'data/icdar2015'\n",
            "icdar2015_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/icdar2015',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "icdar2015_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/icdar2015',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "iiit5k_textrecog_data_root = 'data/iiit5k'\n",
            "iiit5k_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/iiit5k',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "iiit5k_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/iiit5k',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "load_from = 'https://download.openmmlab.com/mmocr/textrecog/abinet/abinet_20e_st-an_mj/abinet_20e_st-an_mj_20221005_012617-ead8c139.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(\n",
            "    _scope_='mmocr', by_epoch=True, type='LogProcessor', window_size=10)\n",
            "mjsynth_sub_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='subset_textrecog_train.json',\n",
            "    data_root='data/mjsynth',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "mjsynth_textrecog_data_root = 'data/mjsynth'\n",
            "mjsynth_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/mjsynth',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "model = dict(\n",
            "    _scope_='mmocr',\n",
            "    backbone=dict(type='ResNetABI'),\n",
            "    data_preprocessor=dict(\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='TextRecogDataPreprocessor'),\n",
            "    decoder=dict(\n",
            "        d_model=512,\n",
            "        dictionary=dict(\n",
            "            dict_file=\n",
            "            '/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/abinet/../../../dicts/lower_english_digits.txt',\n",
            "            same_start_end=True,\n",
            "            type='Dictionary',\n",
            "            with_end=True,\n",
            "            with_padding=False,\n",
            "            with_start=True,\n",
            "            with_unknown=False),\n",
            "        language_decoder=dict(\n",
            "            d_inner=2048,\n",
            "            d_model=512,\n",
            "            detach_tokens=True,\n",
            "            dropout=0.1,\n",
            "            n_head=8,\n",
            "            n_layers=4,\n",
            "            type='ABILanguageDecoder',\n",
            "            use_self_attn=False),\n",
            "        max_seq_len=26,\n",
            "        module_loss=dict(letter_case='lower', type='ABIModuleLoss'),\n",
            "        num_iters=3,\n",
            "        postprocessor=dict(type='AttentionPostprocessor'),\n",
            "        type='ABIFuser',\n",
            "        vision_decoder=dict(\n",
            "            attn_height=8,\n",
            "            attn_mode='nearest',\n",
            "            attn_width=32,\n",
            "            in_channels=512,\n",
            "            init_cfg=dict(layer='Conv2d', type='Xavier'),\n",
            "            num_channels=64,\n",
            "            type='ABIVisionDecoder')),\n",
            "    encoder=dict(\n",
            "        d_inner=2048,\n",
            "        d_model=512,\n",
            "        dropout=0.1,\n",
            "        max_len=256,\n",
            "        n_head=8,\n",
            "        n_layers=3,\n",
            "        type='ABIEncoder'),\n",
            "    type='ABINet')\n",
            "optim_wrapper = dict(\n",
            "    _scope_='mmocr',\n",
            "    optimizer=dict(lr=0.0001, type='Adam'),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        convert_to_iter_based=True,\n",
            "        end=2,\n",
            "        start_factor=0.001,\n",
            "        type='LinearLR'),\n",
            "    dict(_scope_='mmocr', end=20, milestones=[\n",
            "        16,\n",
            "        18,\n",
            "    ], type='MultiStepLR'),\n",
            "]\n",
            "randomness = dict(seed=None)\n",
            "resume = False\n",
            "svt_textrecog_data_root = 'data/svt'\n",
            "svt_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/svt',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "svt_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/svt',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "svtp_textrecog_data_root = 'data/svtp'\n",
            "svtp_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/svtp',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "svtp_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/svtp',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "synthtext_an_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='alphanumeric_textrecog_train.json',\n",
            "    data_root='data/synthtext',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "synthtext_sub_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='subset_textrecog_train.json',\n",
            "    data_root='data/synthtext',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "synthtext_textrecog_data_root = 'data/synthtext'\n",
            "synthtext_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/synthtext',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "test_cfg = dict(_scope_='mmocr', type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=96,\n",
            "    dataset=dict(\n",
            "        ann_file='textrecog_test_truncated.json',\n",
            "        data_root='data/CEGD-R_train_test',\n",
            "        metainfo=dict(mlflow=dict(name='CEGDR-R_recog_trunc')),\n",
            "        pipeline=[\n",
            "            dict(_scope_='mmocr', type='LoadImageFromFile'),\n",
            "            dict(_scope_='mmocr', scale=(\n",
            "                128,\n",
            "                32,\n",
            "            ), type='Resize'),\n",
            "            dict(_scope_='mmocr', type='LoadOCRAnnotations', with_text=True),\n",
            "            dict(\n",
            "                _scope_='mmocr',\n",
            "                meta_keys=(\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'valid_ratio',\n",
            "                ),\n",
            "                type='PackTextRecogInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    num_workers=18,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_dataset = dict(\n",
            "    _scope_='mmocr',\n",
            "    datasets=[\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/cute80',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/iiit5k',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/svt',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/svtp',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/icdar2013',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/icdar2015',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "    ],\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(scale=(\n",
            "            128,\n",
            "            32,\n",
            "        ), type='Resize'),\n",
            "        dict(type='LoadOCRAnnotations', with_text=True),\n",
            "        dict(\n",
            "            meta_keys=(\n",
            "                'img_path',\n",
            "                'ori_shape',\n",
            "                'img_shape',\n",
            "                'valid_ratio',\n",
            "            ),\n",
            "            type='PackTextRecogInputs'),\n",
            "    ],\n",
            "    type='ConcatDataset')\n",
            "test_evaluator = dict(metrics=[\n",
            "    dict(\n",
            "        mode=[\n",
            "            'exact',\n",
            "            'ignore_case',\n",
            "            'ignore_case_symbol',\n",
            "        ],\n",
            "        type='WordMetric'),\n",
            "    dict(type='CharMetric'),\n",
            "])\n",
            "test_list = [\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/cute80',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/iiit5k',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/svt',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/svtp',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/icdar2013',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/icdar2015',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(_scope_='mmocr', type='LoadImageFromFile'),\n",
            "    dict(_scope_='mmocr', scale=(\n",
            "        128,\n",
            "        32,\n",
            "    ), type='Resize'),\n",
            "    dict(_scope_='mmocr', type='LoadOCRAnnotations', with_text=True),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        meta_keys=(\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'valid_ratio',\n",
            "        ),\n",
            "        type='PackTextRecogInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    _scope_='mmocr', max_epochs=1, type='EpochBasedTrainLoop', val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=96,\n",
            "    dataset=dict(\n",
            "        ann_file='textrecog_train_truncated.json',\n",
            "        data_root='data/CEGD-R_train_test',\n",
            "        metainfo=dict(mlflow=dict(name='CEGDR-R_recog_trunc')),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                _scope_='mmocr',\n",
            "                ignore_empty=True,\n",
            "                min_size=2,\n",
            "                type='LoadImageFromFile'),\n",
            "            dict(_scope_='mmocr', type='LoadOCRAnnotations', with_text=True),\n",
            "            dict(_scope_='mmocr', scale=(\n",
            "                128,\n",
            "                32,\n",
            "            ), type='Resize'),\n",
            "            dict(\n",
            "                _scope_='mmocr',\n",
            "                prob=0.5,\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        transforms=[\n",
            "                            dict(max_angle=15, type='RandomRotate'),\n",
            "                            dict(\n",
            "                                degrees=15,\n",
            "                                op='RandomAffine',\n",
            "                                scale=(\n",
            "                                    0.5,\n",
            "                                    2.0,\n",
            "                                ),\n",
            "                                shear=(\n",
            "                                    -45,\n",
            "                                    45,\n",
            "                                ),\n",
            "                                translate=(\n",
            "                                    0.3,\n",
            "                                    0.3,\n",
            "                                ),\n",
            "                                type='TorchVisionWrapper'),\n",
            "                            dict(\n",
            "                                distortion_scale=0.5,\n",
            "                                op='RandomPerspective',\n",
            "                                p=1,\n",
            "                                type='TorchVisionWrapper'),\n",
            "                        ],\n",
            "                        type='RandomChoice'),\n",
            "                ],\n",
            "                type='RandomApply'),\n",
            "            dict(\n",
            "                _scope_='mmocr',\n",
            "                prob=0.25,\n",
            "                transforms=[\n",
            "                    dict(type='PyramidRescale'),\n",
            "                    dict(\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                p=0.5, type='GaussNoise', var_limit=(\n",
            "                                    20,\n",
            "                                    20,\n",
            "                                )),\n",
            "                            dict(blur_limit=7, p=0.5, type='MotionBlur'),\n",
            "                        ],\n",
            "                        type='mmdet.Albu'),\n",
            "                ],\n",
            "                type='RandomApply'),\n",
            "            dict(\n",
            "                _scope_='mmocr',\n",
            "                prob=0.25,\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        brightness=0.5,\n",
            "                        contrast=0.5,\n",
            "                        hue=0.1,\n",
            "                        op='ColorJitter',\n",
            "                        saturation=0.5,\n",
            "                        type='TorchVisionWrapper'),\n",
            "                ],\n",
            "                type='RandomApply'),\n",
            "            dict(\n",
            "                _scope_='mmocr',\n",
            "                meta_keys=(\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'valid_ratio',\n",
            "                ),\n",
            "                type='PackTextRecogInputs'),\n",
            "        ],\n",
            "        type='OCRDataset'),\n",
            "    num_workers=18,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_dataset = dict(\n",
            "    _scope_='mmocr',\n",
            "    datasets=[\n",
            "        dict(\n",
            "            ann_file='textrecog_train.json',\n",
            "            data_root='data/mjsynth',\n",
            "            pipeline=None,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='alphanumeric_textrecog_train.json',\n",
            "            data_root='data/synthtext',\n",
            "            pipeline=None,\n",
            "            type='OCRDataset'),\n",
            "    ],\n",
            "    pipeline=[\n",
            "        dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
            "        dict(type='LoadOCRAnnotations', with_text=True),\n",
            "        dict(scale=(\n",
            "            128,\n",
            "            32,\n",
            "        ), type='Resize'),\n",
            "        dict(\n",
            "            prob=0.5,\n",
            "            transforms=[\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(max_angle=15, type='RandomRotate'),\n",
            "                        dict(\n",
            "                            degrees=15,\n",
            "                            op='RandomAffine',\n",
            "                            scale=(\n",
            "                                0.5,\n",
            "                                2.0,\n",
            "                            ),\n",
            "                            shear=(\n",
            "                                -45,\n",
            "                                45,\n",
            "                            ),\n",
            "                            translate=(\n",
            "                                0.3,\n",
            "                                0.3,\n",
            "                            ),\n",
            "                            type='TorchVisionWrapper'),\n",
            "                        dict(\n",
            "                            distortion_scale=0.5,\n",
            "                            op='RandomPerspective',\n",
            "                            p=1,\n",
            "                            type='TorchVisionWrapper'),\n",
            "                    ],\n",
            "                    type='RandomChoice'),\n",
            "            ],\n",
            "            type='RandomApply'),\n",
            "        dict(\n",
            "            prob=0.25,\n",
            "            transforms=[\n",
            "                dict(type='PyramidRescale'),\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(p=0.5, type='GaussNoise', var_limit=(\n",
            "                            20,\n",
            "                            20,\n",
            "                        )),\n",
            "                        dict(blur_limit=7, p=0.5, type='MotionBlur'),\n",
            "                    ],\n",
            "                    type='mmdet.Albu'),\n",
            "            ],\n",
            "            type='RandomApply'),\n",
            "        dict(\n",
            "            prob=0.25,\n",
            "            transforms=[\n",
            "                dict(\n",
            "                    brightness=0.5,\n",
            "                    contrast=0.5,\n",
            "                    hue=0.1,\n",
            "                    op='ColorJitter',\n",
            "                    saturation=0.5,\n",
            "                    type='TorchVisionWrapper'),\n",
            "            ],\n",
            "            type='RandomApply'),\n",
            "        dict(\n",
            "            meta_keys=(\n",
            "                'img_path',\n",
            "                'ori_shape',\n",
            "                'img_shape',\n",
            "                'valid_ratio',\n",
            "            ),\n",
            "            type='PackTextRecogInputs'),\n",
            "    ],\n",
            "    type='ConcatDataset')\n",
            "train_list = [\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_train.json',\n",
            "        data_root='data/mjsynth',\n",
            "        pipeline=None,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='alphanumeric_textrecog_train.json',\n",
            "        data_root='data/synthtext',\n",
            "        pipeline=None,\n",
            "        type='OCRDataset'),\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ignore_empty=True,\n",
            "        min_size=2,\n",
            "        type='LoadImageFromFile'),\n",
            "    dict(_scope_='mmocr', type='LoadOCRAnnotations', with_text=True),\n",
            "    dict(_scope_='mmocr', scale=(\n",
            "        128,\n",
            "        32,\n",
            "    ), type='Resize'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        prob=0.5,\n",
            "        transforms=[\n",
            "            dict(\n",
            "                transforms=[\n",
            "                    dict(max_angle=15, type='RandomRotate'),\n",
            "                    dict(\n",
            "                        degrees=15,\n",
            "                        op='RandomAffine',\n",
            "                        scale=(\n",
            "                            0.5,\n",
            "                            2.0,\n",
            "                        ),\n",
            "                        shear=(\n",
            "                            -45,\n",
            "                            45,\n",
            "                        ),\n",
            "                        translate=(\n",
            "                            0.3,\n",
            "                            0.3,\n",
            "                        ),\n",
            "                        type='TorchVisionWrapper'),\n",
            "                    dict(\n",
            "                        distortion_scale=0.5,\n",
            "                        op='RandomPerspective',\n",
            "                        p=1,\n",
            "                        type='TorchVisionWrapper'),\n",
            "                ],\n",
            "                type='RandomChoice'),\n",
            "        ],\n",
            "        type='RandomApply'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        prob=0.25,\n",
            "        transforms=[\n",
            "            dict(type='PyramidRescale'),\n",
            "            dict(\n",
            "                transforms=[\n",
            "                    dict(p=0.5, type='GaussNoise', var_limit=(\n",
            "                        20,\n",
            "                        20,\n",
            "                    )),\n",
            "                    dict(blur_limit=7, p=0.5, type='MotionBlur'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "        ],\n",
            "        type='RandomApply'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        prob=0.25,\n",
            "        transforms=[\n",
            "            dict(\n",
            "                brightness=0.5,\n",
            "                contrast=0.5,\n",
            "                hue=0.1,\n",
            "                op='ColorJitter',\n",
            "                saturation=0.5,\n",
            "                type='TorchVisionWrapper'),\n",
            "        ],\n",
            "        type='RandomApply'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        meta_keys=(\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'valid_ratio',\n",
            "        ),\n",
            "        type='PackTextRecogInputs'),\n",
            "]\n",
            "tta_model = dict(_scope_='mmocr', type='EncoderDecoderRecognizerTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(_scope_='mmocr', type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(\n",
            "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
            "                    true_transforms=[\n",
            "                        dict(\n",
            "                            args=[\n",
            "                                dict(cls='Rot90', k=0, keep_size=False),\n",
            "                            ],\n",
            "                            type='ImgAugWrapper'),\n",
            "                    ],\n",
            "                    type='ConditionApply'),\n",
            "                dict(\n",
            "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
            "                    true_transforms=[\n",
            "                        dict(\n",
            "                            args=[\n",
            "                                dict(cls='Rot90', k=1, keep_size=False),\n",
            "                            ],\n",
            "                            type='ImgAugWrapper'),\n",
            "                    ],\n",
            "                    type='ConditionApply'),\n",
            "                dict(\n",
            "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
            "                    true_transforms=[\n",
            "                        dict(\n",
            "                            args=[\n",
            "                                dict(cls='Rot90', k=3, keep_size=False),\n",
            "                            ],\n",
            "                            type='ImgAugWrapper'),\n",
            "                    ],\n",
            "                    type='ConditionApply'),\n",
            "            ],\n",
            "            [\n",
            "                dict(scale=(\n",
            "                    128,\n",
            "                    32,\n",
            "                ), type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadOCRAnnotations', with_text=True),\n",
            "            ],\n",
            "            [\n",
            "                dict(\n",
            "                    meta_keys=(\n",
            "                        'img_path',\n",
            "                        'ori_shape',\n",
            "                        'img_shape',\n",
            "                        'valid_ratio',\n",
            "                    ),\n",
            "                    type='PackTextRecogInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(_scope_='mmocr', type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=96,\n",
            "    dataset=dict(\n",
            "        ann_file='textrecog_test_truncated.json',\n",
            "        data_root='data/CEGD-R_train_test',\n",
            "        metainfo=dict(mlflow=dict(name='CEGDR-R_recog_trunc')),\n",
            "        pipeline=[\n",
            "            dict(_scope_='mmocr', type='LoadImageFromFile'),\n",
            "            dict(_scope_='mmocr', scale=(\n",
            "                128,\n",
            "                32,\n",
            "            ), type='Resize'),\n",
            "            dict(_scope_='mmocr', type='LoadOCRAnnotations', with_text=True),\n",
            "            dict(\n",
            "                _scope_='mmocr',\n",
            "                meta_keys=(\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'valid_ratio',\n",
            "                ),\n",
            "                type='PackTextRecogInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    num_workers=18,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(metrics=[\n",
            "    dict(\n",
            "        mode=[\n",
            "            'exact',\n",
            "            'ignore_case',\n",
            "            'ignore_case_symbol',\n",
            "        ],\n",
            "        type='WordMetric'),\n",
            "    dict(type='CharMetric'),\n",
            "])\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "    dict(\n",
            "        artifact_suffix=(\n",
            "            '.json',\n",
            "            '.log',\n",
            "            '.py',\n",
            "            'yaml',\n",
            "            '.pth',\n",
            "        ),\n",
            "        exp_name='mmocr_recog',\n",
            "        tracking_uri='http://localhost:5000',\n",
            "        type='MLflowVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    name=\n",
            "    'time.struct_time(tm_year=2025, tm_mon=7, tm_mday=14, tm_hour=18, tm_min=33, tm_sec=3, tm_wday=0, tm_yday=195, tm_isdst=0)',\n",
            "    type='TextRecogLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "        dict(\n",
            "            artifact_suffix=(\n",
            "                '.json',\n",
            "                '.log',\n",
            "                '.py',\n",
            "                'yaml',\n",
            "                '.pth',\n",
            "            ),\n",
            "            exp_name='mmocr_recog',\n",
            "            tracking_uri='http://localhost:5000',\n",
            "            type='MLflowVisBackend'),\n",
            "    ])\n",
            "work_dir = 'work_dirs/abinet_custom_cegdr-truncated_dict-original'\n",
            "\n",
            "[VISUALIZER] backends = ['str', 'str']\n",
            "07/14 18:33:04 - mmengine /dev/null \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - Please make sure that the mlflow server is running.\n",
            "07/14 18:33:06 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/models/textrecog/module_losses/ce_module_loss.py:101: UserWarning: padding does not exist in the dictionary\n",
            "  warnings.warn(\n",
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/models/textrecog/postprocessors/base.py:60: UserWarning: padding does not exist in the dictionary\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/14 18:33:06 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------/dev/null \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(LOW         ) MlflowDatasetHook                  \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------/dev/null \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------/dev/null \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------/dev/null \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------/dev/null \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------/dev/null \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------/dev/null \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------/dev/null \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------/dev/null \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------/dev/null \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------/dev/null \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------/dev/null \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------/dev/null \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(LOW         ) MlflowDatasetHook                  \n",
            " -------------------/dev/null \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------/dev/null \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------/dev/null \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------/dev/null \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------/dev/null \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------/dev/null \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------/dev/null \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmdet/datasets/transforms/transforms.py:1674: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
            "  return obj_cls(**args)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/14 18:33:07 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmocr/textrecog/abinet/abinet_20e_st-an_mj/abinet_20e_st-an_mj_20221005_012617-ead8c139.pth\n",
            "07/14 18:33:08 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
            "\n",
            "07/14 18:33:08 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from https://download.openmmlab.com/mmocr/textrecog/abinet/abinet_20e_st-an_mj/abinet_20e_st-an_mj_20221005_012617-ead8c139.pth\n",
            "07/14 18:33:08 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:08 - mmengine /dev/null \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m /dev/null \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "07/14 18:33:08 - mmengine /dev/null \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m /dev/null \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "07/14 18:33:08 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /home/bonting/bonting-identification/work_dirs/abinet_custom_cegdr-truncated_dict-original/20250714_183303/ckpt.\n",
            "07/14 18:33:08 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mlflow/data/dataset_source_registry.py:149: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'data/CEGD-R_train_test'. Exception: \n",
            "  return _dataset_source_registry.resolve(\n",
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mlflow/data/dataset_source_registry.py:149: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
            "  return _dataset_source_registry.resolve(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/14 18:33:08 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmcv/cnn/bricks/transformer.py:819: UserWarning: Use same attn_mask in all attentions in BaseTransformerLayer \n",
            "  warnings.warn(f'Use same attn_mask in all attentions in '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/14 18:33:09 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:09 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:09 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:09 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:09 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:09 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:09 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:09 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:10 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:10 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:10 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:10 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:10 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:10 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:10 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:11 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:11 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:11 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:11 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:11 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:11 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:11 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:12 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:12 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:12 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:12 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:12 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:12 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:12 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:12 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:13 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:13 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:13 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:13 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:13 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:13 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:14 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:14 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:14 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:14 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:14 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:14 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:15 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:15 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:15 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:15 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:15 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:15 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:15 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n",
            "07/14 18:33:15 - mmengine /dev/null \u001b[4m\u001b[97mINFO\u001b[0m - [DEBUG] calling hook <mmocr_custom.hooks.mlflow_dataset_hook.MlflowDatasetHook object at 0x7f4347529b10>\n"
          ]
        }
      ],
      "source": [
        "#@title Train single model\n",
        "\n",
        "from pathlib import Path\n",
        "from mmengine.runner import Runner\n",
        "import time\n",
        "from mmengine import Config\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "if SMOKE_TEST:\n",
        "    load_dotenv() # NOTE: make sure to reload notebook when changing .env to use new env variables\n",
        "\n",
        "    os.chdir(os.path.expanduser('~/bonting-identification'))\n",
        "\n",
        "    if not active_configs:\n",
        "        raise ValueError(\"No active configs found in CONFIG_LIST\")\n",
        "    \n",
        "    # Use the first active config for smoke test\n",
        "    model_config = active_configs[0]\n",
        "\n",
        "    cfg = Config.fromfile(model_config)\n",
        "    cfg['load_from'] = CONFIG_TO_CKPT[model_config]\n",
        "    cfg.visualizer.name = f'{time.localtime()}'\n",
        "\n",
        "    cfg.train_cfg['max_epochs'] = 1 # Optionally, smoke test on 1 epoch\n",
        "\n",
        "    runner = Runner.from_cfg(cfg)\n",
        "    result = runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RESULTS of dict ablation on 1 model\n",
        "\n",
        "# abinet on CEGD-R w/extended dict: recog/word_acc: 0.90 @ 20 epochs\n",
        "# abinet on CEGD-R w/allow unk: recog/word_acc: 0.6320 @ 20 epochs\n",
        "# abinet on CEGD-R-truncated w/original dict: recog/word_acc: 0.93 @ 20 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !rm -rf work_dirs/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Train all models\n",
        "\n",
        "import os\n",
        "from mmengine.runner import Runner\n",
        "import time\n",
        "from mmengine import Config\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if not SMOKE_TEST:\n",
        "    load_dotenv() # NOTE: make sure to reload notebook when changing .env to use new env variables\n",
        "    os.chdir(os.path.expanduser('~/bonting-identification'))\n",
        "\n",
        "    results = []\n",
        "    model_configs = []\n",
        "    ckpts = []\n",
        "\n",
        "    # Determine how many models to train\n",
        "    if NUM_MODELS is None:\n",
        "        # Use all models when NUM_MODELS is None\n",
        "        models_to_train = len(active_configs)\n",
        "    else:\n",
        "        # Use specified number of models\n",
        "        models_to_train = min(NUM_MODELS, len(active_configs))\n",
        "    \n",
        "    for model_config in active_configs[:models_to_train]:\n",
        "        cfg = Config.fromfile(model_config)\n",
        "        cfg['load_from'] = CONFIG_TO_CKPT[model_config]\n",
        "        cfg.visualizer.name = f'{time.localtime()}'\n",
        "\n",
        "        # cfg.train_cfg['max_epochs'] = 1\n",
        "\n",
        "        runner = Runner.from_cfg(cfg)\n",
        "        result = runner.train()\n",
        "\n",
        "        results.append(result)\n",
        "        model_configs.append(Path(model_config).name.rstrip('.py'))\n",
        "        ckpts.append(Path(CONFIG_TO_CKPT[model_config]).parts[-2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results_df = pd.DataFrame(results)\n",
        "# results_df.insert(0, 'model_config', model_configs)\n",
        "# results_df.insert(1, 'ckpt', ckpts)\n",
        "# results_df = results_df.set_index(['model_config', 'ckpt'])\n",
        "# results_df.sort_values('recog/word_acc', ascending=False, inplace=True)\n",
        "# results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save_path = Path('reports/eval/cegdr/textrecog/mmocr_finetuned_recog_results.csv')\n",
        "# save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "# print(f'Saving results to:\\n{save_path}')\n",
        "# results_df.to_csv(save_path, index=True, header=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
