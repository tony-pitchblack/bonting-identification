{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "parameters"
        ]
      },
      "outputs": [],
      "source": [
        "SMOKE_TEST = True\n",
        "# SMOKE_TEST = False\n",
        "\n",
        "TEST_EARLY_STOPPING = False\n",
        "\n",
        "# Number of models to train - None means all models (ignored in smoke test mode)\n",
        "NUM_MODELS = None\n",
        "\n",
        "# Path to YAML config file containing list of model configs to train\n",
        "CONFIG_LIST = 'notebooks/configs/model_lists/textrecog.yml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Ignore all UserWarnings emitted from any submodule of torch\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=UserWarning,\n",
        "    module=r\"torch.*\"\n",
        ")\n",
        "# Ignore all UserWarnings emitted from any submodule of torch\n",
        "warnings.filterwarnings(\n",
        "    \"ignore\",\n",
        "    category=UserWarning,\n",
        "    module=r\"mmcv.*\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 2 active configs:\n",
            "  - configs/textrecog/satrn_custom/satrn_cegdr-truncated_dict-original.py\n",
            "  - configs/textrecog/svtr_custom/svtr_cegdr-truncated_dict-original.py\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Load model configs from YAML file\n",
        "with open(CONFIG_LIST, 'r') as f:\n",
        "    config_paths = yaml.safe_load(f)\n",
        "\n",
        "# Filter out commented lines and empty entries\n",
        "active_configs = [cfg for cfg in config_paths if cfg and not cfg.strip().startswith('#')]\n",
        "\n",
        "# Map model types to checkpoint URLs\n",
        "CHECKPOINT_URLS = {\n",
        "    'abinet_custom': 'https://download.openmmlab.com/mmocr/textrecog/abinet/abinet_20e_st-an_mj/abinet_20e_st-an_mj_20221005_012617-ead8c139.pth',\n",
        "    'abinet-vision_custom': 'https://download.openmmlab.com/mmocr/textrecog/abinet/abinet-vision_20e_st-an_mj/abinet-vision_20e_st-an_mj_20220915_152445-85cfb03d.pth',\n",
        "    'aster_custom': 'https://download.openmmlab.com/mmocr/textrecog/aster/aster_resnet45_6e_st_mj/aster_resnet45_6e_st_mj-cc56eca4.pth',\n",
        "    'crnn_custom': 'https://download.openmmlab.com/mmocr/textrecog/crnn/crnn_mini-vgg_5e_mj/crnn_mini-vgg_5e_mj_20220826_224120-8afbedbb.pth',\n",
        "    'master_custom': 'https://download.openmmlab.com/mmocr/textrecog/master/master_resnet31_12e_st_mj_sa/master_resnet31_12e_st_mj_sa_20220915_152443-f4a5cabc.pth',\n",
        "    'nrtr_custom': 'https://download.openmmlab.com/mmocr/textrecog/nrtr/nrtr_resnet31-1by8-1by4_6e_st_mj/nrtr_resnet31-1by8-1by4_6e_st_mj_20220916_103322-a6a2a123.pth',\n",
        "    'robustscanner_custom': 'https://download.openmmlab.com/mmocr/textrecog/robust_scanner/robustscanner_resnet31_5e_st-sub_mj-sub_sa_real/robustscanner_resnet31_5e_st-sub_mj-sub_sa_real_20220915_152447-7fc35929.pth',\n",
        "    'sar_custom': 'https://download.openmmlab.com/mmocr/textrecog/sar/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real_20220915_171910-04eb4e75.pth',\n",
        "    'satrn_custom': 'https://download.openmmlab.com/mmocr/textrecog/satrn/satrn_shallow_5e_st_mj/satrn_shallow_5e_st_mj_20220915_152443-5fd04a4c.pth',\n",
        "    'svtr_custom': 'https://download.openmmlab.com/mmocr/textrecog/svtr/svtr-base_20e_st_mj/svtr-base_20e_st_mj-ea500101.pth',\n",
        "}\n",
        "\n",
        "# Create mapping from config paths to checkpoint URLs\n",
        "CONFIG_TO_CKPT = {}\n",
        "for config_path in active_configs:\n",
        "    config_path_obj = Path(config_path)\n",
        "    # Extract model type from parent directory name\n",
        "    model_type = config_path_obj.parent.name\n",
        "    if model_type in CHECKPOINT_URLS:\n",
        "        CONFIG_TO_CKPT[config_path] = CHECKPOINT_URLS[model_type]\n",
        "\n",
        "print(f\"Loaded {len(active_configs)} active configs:\")\n",
        "for config in active_configs:\n",
        "    print(f\"  - {config}\")\n",
        "\n",
        "ROOT_CONFIG_FOLDER = 'configs/textrecog'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHneq5LxRT6z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/31 18:06:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Using env variable `MLFLOW_TRACKING_URI` with value of http://127.0.0.1:5000 to replace item in config.\n",
            "07/31 18:06:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Using env variable `MLFLOW_TRACKING_URI` with value of http://127.0.0.1:5000 to replace item in config.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmengine/utils/package_utils.py:17: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  _bootstrap._exec(spec, module)\n"
          ]
        }
      ],
      "source": [
        "#@title Train single model\n",
        "\n",
        "from pathlib import Path\n",
        "from mmengine.runner import Runner\n",
        "import time\n",
        "from mmengine import Config\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "if SMOKE_TEST:\n",
        "    load_dotenv() # NOTE: make sure to reload notebook when changing .env to use new env variables\n",
        "\n",
        "    os.chdir(os.path.expanduser('~/bonting-identification'))\n",
        "\n",
        "    if not active_configs:\n",
        "        raise ValueError(\"No active configs found in CONFIG_LIST\")\n",
        "    \n",
        "    # Use the first active config for smoke test\n",
        "    model_config = active_configs[0]\n",
        "\n",
        "    cfg = Config.fromfile(model_config)\n",
        "    cfg['load_from'] = CONFIG_TO_CKPT[model_config]\n",
        "    cfg.visualizer.name = f'{time.localtime()}'\n",
        "\n",
        "    if TEST_EARLY_STOPPING:\n",
        "        print(\"EARLY STOPPING TEST: 2 epochs\")\n",
        "        cfg.train_cfg['max_epochs'] = 2\n",
        "        for hook in cfg.custom_hooks:\n",
        "            if hook['type'] == 'EarlyStoppingHook':\n",
        "                hook['patience'] = 1\n",
        "                hook['min_delta'] = 1.0\n",
        "                print(f'New hook settings: {hook}')\n",
        "                break\n",
        "    else:\n",
        "        print(\"SMOKE TEST: 1 epoch\")\n",
        "        cfg.train_cfg['max_epochs'] = 1\n",
        "\n",
        "    runner = Runner.from_cfg(cfg)\n",
        "    result = runner.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RESULTS of dict ablation on 1 model\n",
        "\n",
        "# abinet on CEGD-R w/extended dict: recog/word_acc: 0.90 @ 20 epochs\n",
        "# abinet on CEGD-R w/allow unk: recog/word_acc: 0.6320 @ 20 epochs\n",
        "# abinet on CEGD-R-truncated w/original dict: recog/word_acc: 0.93 @ 20 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !rm -rf work_dirs/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Train all models\n",
        "\n",
        "import os\n",
        "from mmengine.runner import Runner\n",
        "import time\n",
        "from mmengine import Config\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "if not SMOKE_TEST:\n",
        "    load_dotenv() # NOTE: make sure to reload notebook when changing .env to use new env variables\n",
        "    os.chdir(os.path.expanduser('~/bonting-identification'))\n",
        "\n",
        "    results = []\n",
        "    model_configs = []\n",
        "    ckpts = []\n",
        "\n",
        "    # Determine how many models to train\n",
        "    if NUM_MODELS is None:\n",
        "        # Use all models when NUM_MODELS is None\n",
        "        models_to_train = len(active_configs)\n",
        "    else:\n",
        "        # Use specified number of models\n",
        "        models_to_train = min(NUM_MODELS, len(active_configs))\n",
        "    \n",
        "    for model_config in active_configs[:models_to_train]:\n",
        "        cfg = Config.fromfile(model_config)\n",
        "        cfg['load_from'] = CONFIG_TO_CKPT[model_config]\n",
        "        cfg.visualizer.name = f'{time.localtime()}'\n",
        "\n",
        "        # cfg.train_cfg['max_epochs'] = 1\n",
        "\n",
        "        runner = Runner.from_cfg(cfg)\n",
        "        result = runner.train()\n",
        "\n",
        "        results.append(result)\n",
        "        model_configs.append(Path(model_config).name.rstrip('.py'))\n",
        "        ckpts.append(Path(CONFIG_TO_CKPT[model_config]).parts[-2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results_df = pd.DataFrame(results)\n",
        "# results_df.insert(0, 'model_config', model_configs)\n",
        "# results_df.insert(1, 'ckpt', ckpts)\n",
        "# results_df = results_df.set_index(['model_config', 'ckpt'])\n",
        "# results_df.sort_values('recog/word_acc', ascending=False, inplace=True)\n",
        "# results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save_path = Path('reports/eval/cegdr/textrecog/mmocr_finetuned_recog_results.csv')\n",
        "# save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "# print(f'Saving results to:\\n{save_path}')\n",
        "# results_df.to_csv(save_path, index=True, header=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
