{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYon41X7RTOT"
      },
      "source": [
        "## Training SAR on a Toy Dataset\n",
        "\n",
        "We now demonstrate how to train a recognizer on a provided dataset in a Python interpreter. Another common practice is to train a model from CLI (command line interface), as illustrated [here](https://mmocr.readthedocs.io/en/dev-1.x/get_started/quick_run.html#training).\n",
        "\n",
        "Since training a full academic dataset is time consuming (usually takes about several hours or even days), we will train on the toy dataset for the SAR text recognition model and visualize the predictions. Text detection and other downstream tasks such as KIE follow similar procedures.\n",
        "\n",
        "Training a model usually consists of the following steps:\n",
        "1. Convert the dataset into [formats supported by MMOCR](https://mmocr.readthedocs.io/en/dev-1.x/basic_concepts/datasets.html). It should never be a concern if the dataset is obtained from Dataset Preparer. Otherwise, you will need to manually download and prepare the dataset following the [guide](https://mmocr.readthedocs.io/en/dev-1.x/user_guides/data_prepare/recog.html), or even have to write a custom conversion script if your dataset is not on the list.\n",
        "2. Modify the config for training. \n",
        "3. Train the model. \n",
        "\n",
        "In this example, we will use an off-the-shelf toy dataset to train SAR, and the first step will be skipped. The full demonstration of the first step can be found at the next section: Evaluating SAR on academic testsets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FElJSp1vpEUz"
      },
      "source": [
        "### Visualize the Toy Dataset\n",
        "\n",
        "We first get a sense of what the toy dataset looks like by visualizing one of the images and labels. The toy dataset consisits of ten images as well as annotation files in both json and lmdb format, and we only use json annotations in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import \\\n",
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmengine/utils/package_utils.py:17: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources\n",
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  _bootstrap._exec(spec, module)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Config (path: /home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/sar/sar_resnet31_parallel-decoder_5e_toy.py): {'toy_data_root': 'tests/data/rec_toy_dataset/', 'toy_rec_train': {'type': 'OCRDataset', 'data_root': 'tests/data/rec_toy_dataset/', 'data_prefix': {'img_path': 'imgs/'}, 'ann_file': 'labels.json', 'pipeline': None, 'test_mode': False}, 'toy_rec_test': {'type': 'OCRDataset', 'data_root': 'tests/data/rec_toy_dataset/', 'data_prefix': {'img_path': 'imgs/'}, 'ann_file': 'labels.json', 'pipeline': None, 'test_mode': True}, 'default_scope': 'mmocr', 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'randomness': {'seed': None}, 'default_hooks': {'timer': {'type': 'IterTimerHook'}, 'logger': {'type': 'LoggerHook', 'interval': 1}, 'param_scheduler': {'type': 'ParamSchedulerHook'}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 1}, 'sampler_seed': {'type': 'DistSamplerSeedHook'}, 'sync_buffer': {'type': 'SyncBuffersHook'}, 'visualization': {'type': 'VisualizationHook', 'interval': 1, 'enable': False, 'show': False, 'draw_gt': False, 'draw_pred': False}}, 'log_level': 'INFO', 'log_processor': {'type': 'LogProcessor', 'window_size': 10, 'by_epoch': True}, 'load_from': None, 'resume': False, 'val_evaluator': {'type': 'MultiDatasetsEvaluator', 'metrics': [{'type': 'WordMetric', 'mode': ['exact', 'ignore_case', 'ignore_case_symbol']}, {'type': 'CharMetric'}], 'dataset_prefixes': ['Toy']}, 'test_evaluator': {'type': 'MultiDatasetsEvaluator', 'metrics': [{'type': 'WordMetric', 'mode': ['exact', 'ignore_case', 'ignore_case_symbol']}, {'type': 'CharMetric'}], 'dataset_prefixes': ['Toy']}, 'vis_backends': [{'type': 'LocalVisBackend'}], 'visualizer': {'type': 'TextRecogLocalVisualizer', 'name': 'visualizer', 'vis_backends': [{'type': 'LocalVisBackend'}]}, 'tta_model': {'type': 'EncoderDecoderRecognizerTTAModel'}, 'optim_wrapper': {'type': 'OptimWrapper', 'optimizer': {'type': 'Adam', 'lr': 0.001}}, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 5, 'val_interval': 1}, 'val_cfg': {'type': 'ValLoop'}, 'test_cfg': {'type': 'TestLoop'}, 'param_scheduler': [{'type': 'MultiStepLR', 'milestones': [3, 4], 'end': 5}], 'dictionary': {'type': 'Dictionary', 'dict_file': '/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/sar/../../../dicts/english_digits_symbols.txt', 'with_start': True, 'with_end': True, 'same_start_end': True, 'with_padding': True, 'with_unknown': True}, 'model': {'type': 'SARNet', 'data_preprocessor': {'type': 'TextRecogDataPreprocessor', 'mean': [127, 127, 127], 'std': [127, 127, 127]}, 'backbone': {'type': 'ResNet31OCR'}, 'encoder': {'type': 'SAREncoder', 'enc_bi_rnn': False, 'enc_do_rnn': 0.1, 'enc_gru': False}, 'decoder': {'type': 'ParallelSARDecoder', 'enc_bi_rnn': False, 'dec_bi_rnn': False, 'dec_do_rnn': 0, 'dec_gru': False, 'pred_dropout': 0.1, 'd_k': 512, 'pred_concat': True, 'postprocessor': {'type': 'AttentionPostprocessor'}, 'module_loss': {'type': 'CEModuleLoss', 'ignore_first_char': True, 'reduction': 'mean'}, 'dictionary': {'type': 'Dictionary', 'dict_file': '/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/sar/../../../dicts/english_digits_symbols.txt', 'with_start': True, 'with_end': True, 'same_start_end': True, 'with_padding': True, 'with_unknown': True}, 'max_seq_len': 30}}, 'train_pipeline': [{'type': 'LoadImageFromFile', 'ignore_empty': True, 'min_size': 2}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'RescaleToHeight', 'height': 48, 'min_width': 48, 'max_width': 160, 'width_divisor': 4}, {'type': 'PadToWidth', 'width': 160}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}], 'test_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'RescaleToHeight', 'height': 48, 'min_width': 48, 'max_width': 160, 'width_divisor': 4}, {'type': 'PadToWidth', 'width': 160}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}], 'tta_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'ConditionApply', 'true_transforms': [{'type': 'ImgAugWrapper', 'args': [{'cls': 'Rot90', 'k': 0, 'keep_size': False}]}], 'condition': \"results['img_shape'][1]<results['img_shape'][0]\"}, {'type': 'ConditionApply', 'true_transforms': [{'type': 'ImgAugWrapper', 'args': [{'cls': 'Rot90', 'k': 1, 'keep_size': False}]}], 'condition': \"results['img_shape'][1]<results['img_shape'][0]\"}, {'type': 'ConditionApply', 'true_transforms': [{'type': 'ImgAugWrapper', 'args': [{'cls': 'Rot90', 'k': 3, 'keep_size': False}]}], 'condition': \"results['img_shape'][1]<results['img_shape'][0]\"}], [{'type': 'RescaleToHeight', 'height': 48, 'min_width': 48, 'max_width': 160, 'width_divisor': 4}], [{'type': 'PadToWidth', 'width': 160}], [{'type': 'LoadOCRAnnotations', 'with_text': True}], [{'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}]]}], 'train_list': [{'type': 'OCRDataset', 'data_root': 'tests/data/rec_toy_dataset/', 'data_prefix': {'img_path': 'imgs/'}, 'ann_file': 'labels.json', 'pipeline': None, 'test_mode': False}], 'test_list': [{'type': 'OCRDataset', 'data_root': 'tests/data/rec_toy_dataset/', 'data_prefix': {'img_path': 'imgs/'}, 'ann_file': 'labels.json', 'pipeline': None, 'test_mode': True}], 'train_dataloader': {'batch_size': 1, 'num_workers': 4, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': True}, 'dataset': {'type': 'ConcatDataset', 'datasets': [{'type': 'OCRDataset', 'data_root': 'tests/data/rec_toy_dataset/', 'data_prefix': {'img_path': 'imgs/'}, 'ann_file': 'labels.json', 'pipeline': None, 'test_mode': False}], 'pipeline': [{'type': 'LoadImageFromFile', 'ignore_empty': True, 'min_size': 2}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'RescaleToHeight', 'height': 48, 'min_width': 48, 'max_width': 160, 'width_divisor': 4}, {'type': 'PadToWidth', 'width': 160}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}]}}, 'val_dataloader': {'batch_size': 1, 'num_workers': 4, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'ConcatDataset', 'datasets': [{'type': 'OCRDataset', 'data_root': 'tests/data/rec_toy_dataset/', 'data_prefix': {'img_path': 'imgs/'}, 'ann_file': 'labels.json', 'pipeline': None, 'test_mode': True}], 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'RescaleToHeight', 'height': 48, 'min_width': 48, 'max_width': 160, 'width_divisor': 4}, {'type': 'PadToWidth', 'width': 160}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}]}}, 'test_dataloader': {'batch_size': 1, 'num_workers': 4, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False}, 'dataset': {'type': 'ConcatDataset', 'datasets': [{'type': 'OCRDataset', 'data_root': 'tests/data/rec_toy_dataset/', 'data_prefix': {'img_path': 'imgs/'}, 'ann_file': 'labels.json', 'pipeline': None, 'test_mode': True}], 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'RescaleToHeight', 'height': 48, 'min_width': 48, 'max_width': 160, 'width_divisor': 4}, {'type': 'PadToWidth', 'width': 160}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}]}}}"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from mmengine.hub import get_config\n",
        "\n",
        "# cfg = get_config('mmocr::textrecog/sar/sar_resnet31_parallel-decoder_5e_toy.py')\n",
        "# cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/bonting/bonting-identification\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  _bootstrap._exec(spec, module)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Config (path: mmocr_configs/cegd-r_evaluation_textrecog.py): {'mjsynth_textrecog_data_root': 'data/mjsynth', 'mjsynth_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/mjsynth', 'ann_file': 'textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'mjsynth_sub_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/mjsynth', 'ann_file': 'subset_textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'synthtext_textrecog_data_root': 'data/synthtext', 'synthtext_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/synthtext', 'ann_file': 'textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'synthtext_sub_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/synthtext', 'ann_file': 'subset_textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'synthtext_an_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/synthtext', 'ann_file': 'alphanumeric_textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'cute80_textrecog_data_root': 'data/cute80', 'cute80_textrecog_test': {'type': 'OCRDataset', 'data_root': 'data/cute80', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, 'iiit5k_textrecog_data_root': 'data/iiit5k', 'iiit5k_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/iiit5k', 'ann_file': 'textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'iiit5k_textrecog_test': {'type': 'OCRDataset', 'data_root': 'data/iiit5k', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, 'svt_textrecog_data_root': 'data/svt', 'svt_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/svt', 'ann_file': 'textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'svt_textrecog_test': {'type': 'OCRDataset', 'data_root': 'data/svt', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, 'svtp_textrecog_data_root': 'data/svtp', 'svtp_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/svtp', 'ann_file': 'textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'svtp_textrecog_test': {'type': 'OCRDataset', 'data_root': 'data/svtp', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, 'icdar2013_textrecog_data_root': 'data/icdar2013', 'icdar2013_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/icdar2013', 'ann_file': 'textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'icdar2013_textrecog_test': {'type': 'OCRDataset', 'data_root': 'data/icdar2013', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, 'icdar2013_857_textrecog_test': {'type': 'OCRDataset', 'data_root': 'data/icdar2013', 'ann_file': 'textrecog_test_857.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, 'icdar2015_textrecog_data_root': 'data/icdar2015', 'icdar2015_textrecog_train': {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, 'icdar2015_textrecog_test': {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, 'icdar2015_1811_textrecog_test': {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textrecog_test_1811.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, 'default_scope': 'mmocr', 'env_cfg': {'cudnn_benchmark': False, 'mp_cfg': {'mp_start_method': 'fork', 'opencv_num_threads': 0}, 'dist_cfg': {'backend': 'nccl'}}, 'randomness': {'seed': None}, 'default_hooks': {'timer': {'type': 'IterTimerHook', '_scope_': 'mmocr'}, 'logger': {'type': 'LoggerHook', 'interval': 100, '_scope_': 'mmocr'}, 'param_scheduler': {'type': 'ParamSchedulerHook', '_scope_': 'mmocr'}, 'checkpoint': {'type': 'CheckpointHook', 'interval': 1, '_scope_': 'mmocr'}, 'sampler_seed': {'type': 'DistSamplerSeedHook', '_scope_': 'mmocr'}, 'sync_buffer': {'type': 'SyncBuffersHook', '_scope_': 'mmocr'}, 'visualization': {'type': 'VisualizationHook', 'interval': 1, 'enable': False, 'show': False, 'draw_gt': False, 'draw_pred': False, '_scope_': 'mmocr'}}, 'log_level': 'INFO', 'log_processor': {'type': 'LogProcessor', 'window_size': 10, 'by_epoch': True, '_scope_': 'mmocr'}, 'load_from': None, 'resume': False, 'val_evaluator': {'type': 'MultiDatasetsEvaluator', 'metrics': [{'type': 'WordMetric', 'mode': ['exact', 'ignore_case', 'ignore_case_symbol']}, {'type': 'CharMetric'}], 'dataset_prefixes': ['CUTE80', 'IIIT5K', 'SVT', 'SVTP', 'IC13', 'IC15'], '_scope_': 'mmocr'}, 'test_evaluator': {'type': 'TextRecogMetric', 'metrics': [{'type': 'WordMetric', 'mode': ['exact', 'ignore_case', 'ignore_case_symbol']}, {'type': 'CharMetric'}], 'dataset_prefixes': ['CUTE80', 'IIIT5K', 'SVT', 'SVTP', 'IC13', 'IC15'], '_scope_': 'mmocr', 'mode': ['rec']}, 'vis_backends': [{'type': 'LocalVisBackend', '_scope_': 'mmocr'}], 'visualizer': {'type': 'TextRecogLocalVisualizer', 'name': 'visualizer', 'vis_backends': [{'type': 'LocalVisBackend'}], '_scope_': 'mmocr'}, 'tta_model': {'type': 'EncoderDecoderRecognizerTTAModel', '_scope_': 'mmocr'}, 'optim_wrapper': {'type': 'OptimWrapper', 'optimizer': {'type': 'Adam', 'lr': 0.0001}, '_scope_': 'mmocr'}, 'train_cfg': {'type': 'EpochBasedTrainLoop', 'max_epochs': 20, 'val_interval': 1, '_scope_': 'mmocr'}, 'val_cfg': {'type': 'ValLoop', '_scope_': 'mmocr'}, 'test_cfg': {'type': 'TestLoop', '_scope_': 'mmocr'}, 'param_scheduler': [{'type': 'LinearLR', 'end': 2, 'start_factor': 0.001, 'convert_to_iter_based': True, '_scope_': 'mmocr'}, {'type': 'MultiStepLR', 'milestones': [16, 18], 'end': 20, '_scope_': 'mmocr'}], 'dictionary': {'type': 'Dictionary', 'dict_file': '/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/abinet/../../../dicts/lower_english_digits.txt', 'with_start': True, 'with_end': True, 'same_start_end': True, 'with_padding': False, 'with_unknown': False, '_scope_': 'mmocr'}, 'model': {'type': 'ABINet', 'backbone': {'type': 'ResNetABI'}, 'encoder': {'type': 'ABIEncoder', 'n_layers': 3, 'n_head': 8, 'd_model': 512, 'd_inner': 2048, 'dropout': 0.1, 'max_len': 256}, 'decoder': {'type': 'ABIFuser', 'vision_decoder': {'type': 'ABIVisionDecoder', 'in_channels': 512, 'num_channels': 64, 'attn_height': 8, 'attn_width': 32, 'attn_mode': 'nearest', 'init_cfg': {'type': 'Xavier', 'layer': 'Conv2d'}}, 'module_loss': {'type': 'ABIModuleLoss', 'letter_case': 'lower'}, 'postprocessor': {'type': 'AttentionPostprocessor'}, 'dictionary': {'type': 'Dictionary', 'dict_file': '/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/abinet/../../../dicts/lower_english_digits.txt', 'with_start': True, 'with_end': True, 'same_start_end': True, 'with_padding': False, 'with_unknown': False}, 'max_seq_len': 26}, 'data_preprocessor': {'type': 'TextRecogDataPreprocessor', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375]}, '_scope_': 'mmocr'}, 'train_pipeline': [{'type': 'LoadImageFromFile', 'ignore_empty': True, 'min_size': 2, '_scope_': 'mmocr'}, {'type': 'LoadOCRAnnotations', 'with_text': True, '_scope_': 'mmocr'}, {'type': 'Resize', 'scale': (128, 32), '_scope_': 'mmocr'}, {'type': 'RandomApply', 'prob': 0.5, 'transforms': [{'type': 'RandomChoice', 'transforms': [{'type': 'RandomRotate', 'max_angle': 15}, {'type': 'TorchVisionWrapper', 'op': 'RandomAffine', 'degrees': 15, 'translate': (0.3, 0.3), 'scale': (0.5, 2.0), 'shear': (-45, 45)}, {'type': 'TorchVisionWrapper', 'op': 'RandomPerspective', 'distortion_scale': 0.5, 'p': 1}]}], '_scope_': 'mmocr'}, {'type': 'RandomApply', 'prob': 0.25, 'transforms': [{'type': 'PyramidRescale'}, {'type': 'mmdet.Albu', 'transforms': [{'type': 'GaussNoise', 'var_limit': (20, 20), 'p': 0.5}, {'type': 'MotionBlur', 'blur_limit': 7, 'p': 0.5}]}], '_scope_': 'mmocr'}, {'type': 'RandomApply', 'prob': 0.25, 'transforms': [{'type': 'TorchVisionWrapper', 'op': 'ColorJitter', 'brightness': 0.5, 'saturation': 0.5, 'contrast': 0.5, 'hue': 0.1}], '_scope_': 'mmocr'}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio'), '_scope_': 'mmocr'}], 'test_pipeline': [Ellipsis], 'tta_pipeline': [{'type': 'LoadImageFromFile', '_scope_': 'mmocr'}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'ConditionApply', 'true_transforms': [{'type': 'ImgAugWrapper', 'args': [{'cls': 'Rot90', 'k': 0, 'keep_size': False}]}], 'condition': \"results['img_shape'][1]<results['img_shape'][0]\"}, {'type': 'ConditionApply', 'true_transforms': [{'type': 'ImgAugWrapper', 'args': [{'cls': 'Rot90', 'k': 1, 'keep_size': False}]}], 'condition': \"results['img_shape'][1]<results['img_shape'][0]\"}, {'type': 'ConditionApply', 'true_transforms': [{'type': 'ImgAugWrapper', 'args': [{'cls': 'Rot90', 'k': 3, 'keep_size': False}]}], 'condition': \"results['img_shape'][1]<results['img_shape'][0]\"}], [{'type': 'Resize', 'scale': (128, 32)}], [{'type': 'LoadOCRAnnotations', 'with_text': True}], [{'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}]], '_scope_': 'mmocr'}], 'train_list': [{'type': 'OCRDataset', 'data_root': 'data/mjsynth', 'ann_file': 'textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}, {'type': 'OCRDataset', 'data_root': 'data/synthtext', 'ann_file': 'alphanumeric_textrecog_train.json', 'pipeline': None, '_scope_': 'mmocr'}], 'test_list': [{'type': 'OCRDataset', 'data_root': 'data/cute80', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, {'type': 'OCRDataset', 'data_root': 'data/iiit5k', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, {'type': 'OCRDataset', 'data_root': 'data/svt', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, {'type': 'OCRDataset', 'data_root': 'data/svtp', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, {'type': 'OCRDataset', 'data_root': 'data/icdar2013', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}, {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None, '_scope_': 'mmocr'}], 'train_dataset': {'type': 'ConcatDataset', 'datasets': [{'type': 'OCRDataset', 'data_root': 'data/mjsynth', 'ann_file': 'textrecog_train.json', 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/synthtext', 'ann_file': 'alphanumeric_textrecog_train.json', 'pipeline': None}], 'pipeline': [{'type': 'LoadImageFromFile', 'ignore_empty': True, 'min_size': 2}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'Resize', 'scale': (128, 32)}, {'type': 'RandomApply', 'prob': 0.5, 'transforms': [{'type': 'RandomChoice', 'transforms': [{'type': 'RandomRotate', 'max_angle': 15}, {'type': 'TorchVisionWrapper', 'op': 'RandomAffine', 'degrees': 15, 'translate': (0.3, 0.3), 'scale': (0.5, 2.0), 'shear': (-45, 45)}, {'type': 'TorchVisionWrapper', 'op': 'RandomPerspective', 'distortion_scale': 0.5, 'p': 1}]}]}, {'type': 'RandomApply', 'prob': 0.25, 'transforms': [{'type': 'PyramidRescale'}, {'type': 'mmdet.Albu', 'transforms': [{'type': 'GaussNoise', 'var_limit': (20, 20), 'p': 0.5}, {'type': 'MotionBlur', 'blur_limit': 7, 'p': 0.5}]}]}, {'type': 'RandomApply', 'prob': 0.25, 'transforms': [{'type': 'TorchVisionWrapper', 'op': 'ColorJitter', 'brightness': 0.5, 'saturation': 0.5, 'contrast': 0.5, 'hue': 0.1}]}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}], '_scope_': 'mmocr'}, 'test_dataset': {'type': 'ConcatDataset', 'datasets': [{'type': 'OCRDataset', 'data_root': 'data/cute80', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/iiit5k', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/svt', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/svtp', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/icdar2013', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}], 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'Resize', 'scale': (128, 32)}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}], '_scope_': 'mmocr'}, 'train_dataloader': {'batch_size': 768, 'num_workers': 32, 'persistent_workers': True, 'sampler': {'type': 'DefaultSampler', 'shuffle': True, '_scope_': 'mmocr'}, 'dataset': {'type': 'ConcatDataset', 'datasets': [{'type': 'OCRDataset', 'data_root': 'data/mjsynth', 'ann_file': 'textrecog_train.json', 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/synthtext', 'ann_file': 'alphanumeric_textrecog_train.json', 'pipeline': None}], 'pipeline': [{'type': 'LoadImageFromFile', 'ignore_empty': True, 'min_size': 2}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'Resize', 'scale': (128, 32)}, {'type': 'RandomApply', 'prob': 0.5, 'transforms': [{'type': 'RandomChoice', 'transforms': [{'type': 'RandomRotate', 'max_angle': 15}, {'type': 'TorchVisionWrapper', 'op': 'RandomAffine', 'degrees': 15, 'translate': (0.3, 0.3), 'scale': (0.5, 2.0), 'shear': (-45, 45)}, {'type': 'TorchVisionWrapper', 'op': 'RandomPerspective', 'distortion_scale': 0.5, 'p': 1}]}]}, {'type': 'RandomApply', 'prob': 0.25, 'transforms': [{'type': 'PyramidRescale'}, {'type': 'mmdet.Albu', 'transforms': [{'type': 'GaussNoise', 'var_limit': (20, 20), 'p': 0.5}, {'type': 'MotionBlur', 'blur_limit': 7, 'p': 0.5}]}]}, {'type': 'RandomApply', 'prob': 0.25, 'transforms': [{'type': 'TorchVisionWrapper', 'op': 'ColorJitter', 'brightness': 0.5, 'saturation': 0.5, 'contrast': 0.5, 'hue': 0.1}]}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}], '_scope_': 'mmocr'}}, 'test_dataloader': {'batch_size': 1, 'num_workers': 4, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False, '_scope_': 'mmocr'}, 'dataset': {'type': 'OCRDataset', 'datasets': [{'type': 'OCRDataset', 'data_root': 'data/cute80', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/iiit5k', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/svt', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/svtp', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/icdar2013', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}], 'pipeline': [Ellipsis], '_scope_': 'mmocr', 'ann_file': 'annotations/', 'img_prefix': 'images/', 'test_mode': True}}, 'val_dataloader': {'batch_size': 1, 'num_workers': 4, 'persistent_workers': True, 'drop_last': False, 'sampler': {'type': 'DefaultSampler', 'shuffle': False, '_scope_': 'mmocr'}, 'dataset': {'type': 'ConcatDataset', 'datasets': [{'type': 'OCRDataset', 'data_root': 'data/cute80', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/iiit5k', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/svt', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/svtp', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/icdar2013', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}, {'type': 'OCRDataset', 'data_root': 'data/icdar2015', 'ann_file': 'textrecog_test.json', 'test_mode': True, 'pipeline': None}], 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'Resize', 'scale': (128, 32)}, {'type': 'LoadOCRAnnotations', 'with_text': True}, {'type': 'PackTextRecogInputs', 'meta_keys': ('img_path', 'ori_shape', 'img_shape', 'valid_ratio')}], '_scope_': 'mmocr'}}, 'auto_scale_lr': {'base_batch_size': 1536}, 'dataset_type': 'OCRDataset', 'data_root': 'data/cegdr_mmocr/', 'work_dir': 'work_dirs/cegd-r_evaluation_textrecog'}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mmengine import Config\n",
        "\n",
        "%cd ~/bonting-identification\n",
        "cfg = Config.fromfile('mmocr_configs/CEGD-R_evaluation_textrecog.py')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTWMzvd3E_h8"
      },
      "source": [
        "## Evaluating SAR\n",
        "\n",
        "This section provides guidance on how to evaluate a model using with pretrained weights in a Python interpreter. Apart from such a practice, another common practice is to test a model from CLI (command line interface), as illustrated [here](https://mmocr.readthedocs.io/en/dev-1.x/get_started/quick_run.html#testing).\n",
        "\n",
        "Typically, the evaluation process involves several steps:\n",
        "\n",
        "1. Convert the dataset into [formats supported by MMOCR](https://mmocr.readthedocs.io/en/dev-1.x/basic_concepts/datasets.html). It should not be a concern if the dataset is obtained from [Dataset Preparer](https://mmocr.readthedocs.io/en/dev-1.x/user_guides/data_prepare/dataset_preparer.html), which can download, extract and convert the dataset into a MMOCR-ready form with a single line of command. Otherwise, you will need to manually download and prepare the dataset following the [guide](https://mmocr.readthedocs.io/en/dev-1.x/user_guides/data_prepare/det.html), or even have to write a custom conversion script if your dataset is not on the list.\n",
        "2. Modify the config for testing. \n",
        "3. Test the model. \n",
        "\n",
        "Now we will demonstrate how to test a model on different datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxehFhP7N_xf"
      },
      "source": [
        "### Toy Dataset\n",
        "\n",
        "With the checkpoint we obtained from the last section, we can evaluate it on the toy dataset again. Some more explanataions about the evaulation metrics are available [here](https://mmocr.readthedocs.io/en/dev-1.x/basic_concepts/evaluation.html). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHneq5LxRT6z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/bonting/bonting-identification\n",
            "07/10 13:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.11.13 | packaged by conda-forge | (main, Jun  4 2025, 14:48:23) [GCC 13.3.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1089348508\n",
            "    GPU 0: NVIDIA GeForce RTX 3090\n",
            "    CUDA_HOME: /opt/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.9, V12.9.86\n",
            "    GCC: gcc (GCC) 15.1.1 20250425\n",
            "    PyTorch: 2.4.1\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 11.4\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2024.2.2-Product Build 20240823 for Intel(R) 64 architecture applications\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_35,code=sm_35;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_89,code=sm_89;-gencode;arch=compute_89,code=compute_89\n",
            "  - CuDNN 91.0.1\n",
            "    - Built with CuDNN 90.8\n",
            "  - Magma 2.9.0\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=9.8.0, CXX_COMPILER=/home/conda/feedstock_root/build_artifacts/libtorch_1742446601637/_build_env/bin/x86_64-conda-linux-gnu-c++, CXX_FLAGS=-fmessage-length=0 -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/conda/feedstock_root/build_artifacts/libtorch_1742446601637/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl/include -fdebug-prefix-map=/home/conda/feedstock_root/build_artifacts/libtorch_1742446601637/work=/usr/local/src/conda/libtorch-2.4.1 -fdebug-prefix-map=/home/conda/feedstock_root/build_artifacts/libtorch_1742446601637/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_pl=/usr/local/src/conda-prefix -isystem /usr/local/cuda/include -Wno-deprecated-declarations -Wno-error=maybe-uninitialized -D_GLIBCXX_USE_CXX11_ABI=1 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.1, USE_CUDA=1, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
            "\n",
            "    TorchVision: 0.19.1\n",
            "    OpenCV: 4.10.0\n",
            "    MMEngine: 0.10.7\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1089348508\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  _bootstrap._exec(spec, module)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/10 13:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "auto_scale_lr = dict(base_batch_size=1536)\n",
            "cute80_textrecog_data_root = 'data/cute80'\n",
            "cute80_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/cute80',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "data_root = 'data/CEGD-R_MMOCR/'\n",
            "dataset_type = 'OCRDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(_scope_='mmocr', interval=1, type='CheckpointHook'),\n",
            "    logger=dict(_scope_='mmocr', interval=100, type='LoggerHook'),\n",
            "    param_scheduler=dict(_scope_='mmocr', type='ParamSchedulerHook'),\n",
            "    sampler_seed=dict(_scope_='mmocr', type='DistSamplerSeedHook'),\n",
            "    sync_buffer=dict(_scope_='mmocr', type='SyncBuffersHook'),\n",
            "    timer=dict(_scope_='mmocr', type='IterTimerHook'),\n",
            "    visualization=dict(\n",
            "        _scope_='mmocr',\n",
            "        draw_gt=False,\n",
            "        draw_pred=False,\n",
            "        enable=False,\n",
            "        interval=1,\n",
            "        show=False,\n",
            "        type='VisualizationHook'))\n",
            "default_scope = 'mmocr'\n",
            "dictionary = dict(\n",
            "    _scope_='mmocr',\n",
            "    dict_file=\n",
            "    '/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/abinet/../../../dicts/lower_english_digits.txt',\n",
            "    same_start_end=True,\n",
            "    type='Dictionary',\n",
            "    with_end=True,\n",
            "    with_padding=False,\n",
            "    with_start=True,\n",
            "    with_unknown=False)\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "icdar2013_857_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test_857.json',\n",
            "    data_root='data/icdar2013',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "icdar2013_textrecog_data_root = 'data/icdar2013'\n",
            "icdar2013_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/icdar2013',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "icdar2013_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/icdar2013',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "icdar2015_1811_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test_1811.json',\n",
            "    data_root='data/icdar2015',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "icdar2015_textrecog_data_root = 'data/icdar2015'\n",
            "icdar2015_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/icdar2015',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "icdar2015_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/icdar2015',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "iiit5k_textrecog_data_root = 'data/iiit5k'\n",
            "iiit5k_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/iiit5k',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "iiit5k_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/iiit5k',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "load_from = 'ckpt/pretrained_mmocr/abinet-vision_20e_st-an_mj_20220915_152445-85cfb03d.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(\n",
            "    _scope_='mmocr', by_epoch=True, type='LogProcessor', window_size=10)\n",
            "mjsynth_sub_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='subset_textrecog_train.json',\n",
            "    data_root='data/mjsynth',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "mjsynth_textrecog_data_root = 'data/mjsynth'\n",
            "mjsynth_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/mjsynth',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "model = dict(\n",
            "    _scope_='mmocr',\n",
            "    backbone=dict(type='ResNetABI'),\n",
            "    data_preprocessor=dict(\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='TextRecogDataPreprocessor'),\n",
            "    decoder=dict(\n",
            "        dictionary=dict(\n",
            "            dict_file=\n",
            "            '/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/.mim/configs/textrecog/abinet/../../../dicts/lower_english_digits.txt',\n",
            "            same_start_end=True,\n",
            "            type='Dictionary',\n",
            "            with_end=True,\n",
            "            with_padding=False,\n",
            "            with_start=True,\n",
            "            with_unknown=False),\n",
            "        max_seq_len=26,\n",
            "        module_loss=dict(letter_case='lower', type='ABIModuleLoss'),\n",
            "        postprocessor=dict(type='AttentionPostprocessor'),\n",
            "        type='ABIFuser',\n",
            "        vision_decoder=dict(\n",
            "            attn_height=8,\n",
            "            attn_mode='nearest',\n",
            "            attn_width=32,\n",
            "            in_channels=512,\n",
            "            init_cfg=dict(layer='Conv2d', type='Xavier'),\n",
            "            num_channels=64,\n",
            "            type='ABIVisionDecoder')),\n",
            "    encoder=dict(\n",
            "        d_inner=2048,\n",
            "        d_model=512,\n",
            "        dropout=0.1,\n",
            "        max_len=256,\n",
            "        n_head=8,\n",
            "        n_layers=3,\n",
            "        type='ABIEncoder'),\n",
            "    type='ABINet')\n",
            "optim_wrapper = dict(\n",
            "    _scope_='mmocr',\n",
            "    optimizer=dict(lr=0.0001, type='Adam'),\n",
            "    type='OptimWrapper')\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        convert_to_iter_based=True,\n",
            "        end=2,\n",
            "        start_factor=0.001,\n",
            "        type='LinearLR'),\n",
            "    dict(_scope_='mmocr', end=20, milestones=[\n",
            "        16,\n",
            "        18,\n",
            "    ], type='MultiStepLR'),\n",
            "]\n",
            "randomness = dict(seed=None)\n",
            "resume = False\n",
            "svt_textrecog_data_root = 'data/svt'\n",
            "svt_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/svt',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "svt_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/svt',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "svtp_textrecog_data_root = 'data/svtp'\n",
            "svtp_textrecog_test = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_test.json',\n",
            "    data_root='data/svtp',\n",
            "    pipeline=None,\n",
            "    test_mode=True,\n",
            "    type='OCRDataset')\n",
            "svtp_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/svtp',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "synthtext_an_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='alphanumeric_textrecog_train.json',\n",
            "    data_root='data/synthtext',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "synthtext_sub_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='subset_textrecog_train.json',\n",
            "    data_root='data/synthtext',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "synthtext_textrecog_data_root = 'data/synthtext'\n",
            "synthtext_textrecog_train = dict(\n",
            "    _scope_='mmocr',\n",
            "    ann_file='textrecog_train.json',\n",
            "    data_root='data/synthtext',\n",
            "    pipeline=None,\n",
            "    type='OCRDataset')\n",
            "test_cfg = dict(_scope_='mmocr', type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='annotations/test.json',\n",
            "        data_root='data/CEGD-R_MMOCR/',\n",
            "        pipeline=[\n",
            "            dict(_scope_='mmocr', type='LoadImageFromFile'),\n",
            "            dict(_scope_='mmocr', scale=(\n",
            "                128,\n",
            "                32,\n",
            "            ), type='Resize'),\n",
            "            dict(_scope_='mmocr', type='LoadOCRAnnotations', with_text=True),\n",
            "            dict(\n",
            "                _scope_='mmocr',\n",
            "                meta_keys=(\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'valid_ratio',\n",
            "                ),\n",
            "                type='PackTextRecogInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(_scope_='mmocr', shuffle=False, type='DefaultSampler'))\n",
            "test_dataset = dict(\n",
            "    _scope_='mmocr',\n",
            "    datasets=[\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/cute80',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/iiit5k',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/svt',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/svtp',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/icdar2013',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='textrecog_test.json',\n",
            "            data_root='data/icdar2015',\n",
            "            pipeline=None,\n",
            "            test_mode=True,\n",
            "            type='OCRDataset'),\n",
            "    ],\n",
            "    pipeline=[\n",
            "        dict(type='LoadImageFromFile'),\n",
            "        dict(scale=(\n",
            "            128,\n",
            "            32,\n",
            "        ), type='Resize'),\n",
            "        dict(type='LoadOCRAnnotations', with_text=True),\n",
            "        dict(\n",
            "            meta_keys=(\n",
            "                'img_path',\n",
            "                'ori_shape',\n",
            "                'img_shape',\n",
            "                'valid_ratio',\n",
            "            ),\n",
            "            type='PackTextRecogInputs'),\n",
            "    ],\n",
            "    type='ConcatDataset')\n",
            "test_evaluator = dict(metrics=[\n",
            "    dict(\n",
            "        mode=[\n",
            "            'exact',\n",
            "            'ignore_case',\n",
            "            'ignore_case_symbol',\n",
            "        ],\n",
            "        type='WordMetric'),\n",
            "    dict(type='CharMetric'),\n",
            "])\n",
            "test_list = [\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/cute80',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/iiit5k',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/svt',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/svtp',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/icdar2013',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_test.json',\n",
            "        data_root='data/icdar2015',\n",
            "        pipeline=None,\n",
            "        test_mode=True,\n",
            "        type='OCRDataset'),\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(_scope_='mmocr', type='LoadImageFromFile'),\n",
            "    dict(_scope_='mmocr', scale=(\n",
            "        128,\n",
            "        32,\n",
            "    ), type='Resize'),\n",
            "    dict(_scope_='mmocr', type='LoadOCRAnnotations', with_text=True),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        meta_keys=(\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'valid_ratio',\n",
            "        ),\n",
            "        type='PackTextRecogInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    _scope_='mmocr', max_epochs=20, type='EpochBasedTrainLoop', val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=768,\n",
            "    dataset=dict(\n",
            "        _scope_='mmocr',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                ann_file='textrecog_train.json',\n",
            "                data_root='data/mjsynth',\n",
            "                pipeline=None,\n",
            "                type='OCRDataset'),\n",
            "            dict(\n",
            "                ann_file='alphanumeric_textrecog_train.json',\n",
            "                data_root='data/synthtext',\n",
            "                pipeline=None,\n",
            "                type='OCRDataset'),\n",
            "        ],\n",
            "        pipeline=[\n",
            "            dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
            "            dict(type='LoadOCRAnnotations', with_text=True),\n",
            "            dict(scale=(\n",
            "                128,\n",
            "                32,\n",
            "            ), type='Resize'),\n",
            "            dict(\n",
            "                prob=0.5,\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        transforms=[\n",
            "                            dict(max_angle=15, type='RandomRotate'),\n",
            "                            dict(\n",
            "                                degrees=15,\n",
            "                                op='RandomAffine',\n",
            "                                scale=(\n",
            "                                    0.5,\n",
            "                                    2.0,\n",
            "                                ),\n",
            "                                shear=(\n",
            "                                    -45,\n",
            "                                    45,\n",
            "                                ),\n",
            "                                translate=(\n",
            "                                    0.3,\n",
            "                                    0.3,\n",
            "                                ),\n",
            "                                type='TorchVisionWrapper'),\n",
            "                            dict(\n",
            "                                distortion_scale=0.5,\n",
            "                                op='RandomPerspective',\n",
            "                                p=1,\n",
            "                                type='TorchVisionWrapper'),\n",
            "                        ],\n",
            "                        type='RandomChoice'),\n",
            "                ],\n",
            "                type='RandomApply'),\n",
            "            dict(\n",
            "                prob=0.25,\n",
            "                transforms=[\n",
            "                    dict(type='PyramidRescale'),\n",
            "                    dict(\n",
            "                        transforms=[\n",
            "                            dict(\n",
            "                                p=0.5, type='GaussNoise', var_limit=(\n",
            "                                    20,\n",
            "                                    20,\n",
            "                                )),\n",
            "                            dict(blur_limit=7, p=0.5, type='MotionBlur'),\n",
            "                        ],\n",
            "                        type='mmdet.Albu'),\n",
            "                ],\n",
            "                type='RandomApply'),\n",
            "            dict(\n",
            "                prob=0.25,\n",
            "                transforms=[\n",
            "                    dict(\n",
            "                        brightness=0.5,\n",
            "                        contrast=0.5,\n",
            "                        hue=0.1,\n",
            "                        op='ColorJitter',\n",
            "                        saturation=0.5,\n",
            "                        type='TorchVisionWrapper'),\n",
            "                ],\n",
            "                type='RandomApply'),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'valid_ratio',\n",
            "                ),\n",
            "                type='PackTextRecogInputs'),\n",
            "        ],\n",
            "        type='ConcatDataset'),\n",
            "    num_workers=32,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(_scope_='mmocr', shuffle=True, type='DefaultSampler'))\n",
            "train_dataset = dict(\n",
            "    _scope_='mmocr',\n",
            "    datasets=[\n",
            "        dict(\n",
            "            ann_file='textrecog_train.json',\n",
            "            data_root='data/mjsynth',\n",
            "            pipeline=None,\n",
            "            type='OCRDataset'),\n",
            "        dict(\n",
            "            ann_file='alphanumeric_textrecog_train.json',\n",
            "            data_root='data/synthtext',\n",
            "            pipeline=None,\n",
            "            type='OCRDataset'),\n",
            "    ],\n",
            "    pipeline=[\n",
            "        dict(ignore_empty=True, min_size=2, type='LoadImageFromFile'),\n",
            "        dict(type='LoadOCRAnnotations', with_text=True),\n",
            "        dict(scale=(\n",
            "            128,\n",
            "            32,\n",
            "        ), type='Resize'),\n",
            "        dict(\n",
            "            prob=0.5,\n",
            "            transforms=[\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(max_angle=15, type='RandomRotate'),\n",
            "                        dict(\n",
            "                            degrees=15,\n",
            "                            op='RandomAffine',\n",
            "                            scale=(\n",
            "                                0.5,\n",
            "                                2.0,\n",
            "                            ),\n",
            "                            shear=(\n",
            "                                -45,\n",
            "                                45,\n",
            "                            ),\n",
            "                            translate=(\n",
            "                                0.3,\n",
            "                                0.3,\n",
            "                            ),\n",
            "                            type='TorchVisionWrapper'),\n",
            "                        dict(\n",
            "                            distortion_scale=0.5,\n",
            "                            op='RandomPerspective',\n",
            "                            p=1,\n",
            "                            type='TorchVisionWrapper'),\n",
            "                    ],\n",
            "                    type='RandomChoice'),\n",
            "            ],\n",
            "            type='RandomApply'),\n",
            "        dict(\n",
            "            prob=0.25,\n",
            "            transforms=[\n",
            "                dict(type='PyramidRescale'),\n",
            "                dict(\n",
            "                    transforms=[\n",
            "                        dict(p=0.5, type='GaussNoise', var_limit=(\n",
            "                            20,\n",
            "                            20,\n",
            "                        )),\n",
            "                        dict(blur_limit=7, p=0.5, type='MotionBlur'),\n",
            "                    ],\n",
            "                    type='mmdet.Albu'),\n",
            "            ],\n",
            "            type='RandomApply'),\n",
            "        dict(\n",
            "            prob=0.25,\n",
            "            transforms=[\n",
            "                dict(\n",
            "                    brightness=0.5,\n",
            "                    contrast=0.5,\n",
            "                    hue=0.1,\n",
            "                    op='ColorJitter',\n",
            "                    saturation=0.5,\n",
            "                    type='TorchVisionWrapper'),\n",
            "            ],\n",
            "            type='RandomApply'),\n",
            "        dict(\n",
            "            meta_keys=(\n",
            "                'img_path',\n",
            "                'ori_shape',\n",
            "                'img_shape',\n",
            "                'valid_ratio',\n",
            "            ),\n",
            "            type='PackTextRecogInputs'),\n",
            "    ],\n",
            "    type='ConcatDataset')\n",
            "train_list = [\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='textrecog_train.json',\n",
            "        data_root='data/mjsynth',\n",
            "        pipeline=None,\n",
            "        type='OCRDataset'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ann_file='alphanumeric_textrecog_train.json',\n",
            "        data_root='data/synthtext',\n",
            "        pipeline=None,\n",
            "        type='OCRDataset'),\n",
            "]\n",
            "train_pipeline = [\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        ignore_empty=True,\n",
            "        min_size=2,\n",
            "        type='LoadImageFromFile'),\n",
            "    dict(_scope_='mmocr', type='LoadOCRAnnotations', with_text=True),\n",
            "    dict(_scope_='mmocr', scale=(\n",
            "        128,\n",
            "        32,\n",
            "    ), type='Resize'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        prob=0.5,\n",
            "        transforms=[\n",
            "            dict(\n",
            "                transforms=[\n",
            "                    dict(max_angle=15, type='RandomRotate'),\n",
            "                    dict(\n",
            "                        degrees=15,\n",
            "                        op='RandomAffine',\n",
            "                        scale=(\n",
            "                            0.5,\n",
            "                            2.0,\n",
            "                        ),\n",
            "                        shear=(\n",
            "                            -45,\n",
            "                            45,\n",
            "                        ),\n",
            "                        translate=(\n",
            "                            0.3,\n",
            "                            0.3,\n",
            "                        ),\n",
            "                        type='TorchVisionWrapper'),\n",
            "                    dict(\n",
            "                        distortion_scale=0.5,\n",
            "                        op='RandomPerspective',\n",
            "                        p=1,\n",
            "                        type='TorchVisionWrapper'),\n",
            "                ],\n",
            "                type='RandomChoice'),\n",
            "        ],\n",
            "        type='RandomApply'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        prob=0.25,\n",
            "        transforms=[\n",
            "            dict(type='PyramidRescale'),\n",
            "            dict(\n",
            "                transforms=[\n",
            "                    dict(p=0.5, type='GaussNoise', var_limit=(\n",
            "                        20,\n",
            "                        20,\n",
            "                    )),\n",
            "                    dict(blur_limit=7, p=0.5, type='MotionBlur'),\n",
            "                ],\n",
            "                type='mmdet.Albu'),\n",
            "        ],\n",
            "        type='RandomApply'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        prob=0.25,\n",
            "        transforms=[\n",
            "            dict(\n",
            "                brightness=0.5,\n",
            "                contrast=0.5,\n",
            "                hue=0.1,\n",
            "                op='ColorJitter',\n",
            "                saturation=0.5,\n",
            "                type='TorchVisionWrapper'),\n",
            "        ],\n",
            "        type='RandomApply'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        meta_keys=(\n",
            "            'img_path',\n",
            "            'ori_shape',\n",
            "            'img_shape',\n",
            "            'valid_ratio',\n",
            "        ),\n",
            "        type='PackTextRecogInputs'),\n",
            "]\n",
            "tta_model = dict(_scope_='mmocr', type='EncoderDecoderRecognizerTTAModel')\n",
            "tta_pipeline = [\n",
            "    dict(_scope_='mmocr', type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        _scope_='mmocr',\n",
            "        transforms=[\n",
            "            [\n",
            "                dict(\n",
            "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
            "                    true_transforms=[\n",
            "                        dict(\n",
            "                            args=[\n",
            "                                dict(cls='Rot90', k=0, keep_size=False),\n",
            "                            ],\n",
            "                            type='ImgAugWrapper'),\n",
            "                    ],\n",
            "                    type='ConditionApply'),\n",
            "                dict(\n",
            "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
            "                    true_transforms=[\n",
            "                        dict(\n",
            "                            args=[\n",
            "                                dict(cls='Rot90', k=1, keep_size=False),\n",
            "                            ],\n",
            "                            type='ImgAugWrapper'),\n",
            "                    ],\n",
            "                    type='ConditionApply'),\n",
            "                dict(\n",
            "                    condition=\"results['img_shape'][1]<results['img_shape'][0]\",\n",
            "                    true_transforms=[\n",
            "                        dict(\n",
            "                            args=[\n",
            "                                dict(cls='Rot90', k=3, keep_size=False),\n",
            "                            ],\n",
            "                            type='ImgAugWrapper'),\n",
            "                    ],\n",
            "                    type='ConditionApply'),\n",
            "            ],\n",
            "            [\n",
            "                dict(scale=(\n",
            "                    128,\n",
            "                    32,\n",
            "                ), type='Resize'),\n",
            "            ],\n",
            "            [\n",
            "                dict(type='LoadOCRAnnotations', with_text=True),\n",
            "            ],\n",
            "            [\n",
            "                dict(\n",
            "                    meta_keys=(\n",
            "                        'img_path',\n",
            "                        'ori_shape',\n",
            "                        'img_shape',\n",
            "                        'valid_ratio',\n",
            "                    ),\n",
            "                    type='PackTextRecogInputs'),\n",
            "            ],\n",
            "        ],\n",
            "        type='TestTimeAug'),\n",
            "]\n",
            "val_cfg = dict(_scope_='mmocr', type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        _scope_='mmocr',\n",
            "        datasets=[\n",
            "            dict(\n",
            "                ann_file='textrecog_test.json',\n",
            "                data_root='data/cute80',\n",
            "                pipeline=None,\n",
            "                test_mode=True,\n",
            "                type='OCRDataset'),\n",
            "            dict(\n",
            "                ann_file='textrecog_test.json',\n",
            "                data_root='data/iiit5k',\n",
            "                pipeline=None,\n",
            "                test_mode=True,\n",
            "                type='OCRDataset'),\n",
            "            dict(\n",
            "                ann_file='textrecog_test.json',\n",
            "                data_root='data/svt',\n",
            "                pipeline=None,\n",
            "                test_mode=True,\n",
            "                type='OCRDataset'),\n",
            "            dict(\n",
            "                ann_file='textrecog_test.json',\n",
            "                data_root='data/svtp',\n",
            "                pipeline=None,\n",
            "                test_mode=True,\n",
            "                type='OCRDataset'),\n",
            "            dict(\n",
            "                ann_file='textrecog_test.json',\n",
            "                data_root='data/icdar2013',\n",
            "                pipeline=None,\n",
            "                test_mode=True,\n",
            "                type='OCRDataset'),\n",
            "            dict(\n",
            "                ann_file='textrecog_test.json',\n",
            "                data_root='data/icdar2015',\n",
            "                pipeline=None,\n",
            "                test_mode=True,\n",
            "                type='OCRDataset'),\n",
            "        ],\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(scale=(\n",
            "                128,\n",
            "                32,\n",
            "            ), type='Resize'),\n",
            "            dict(type='LoadOCRAnnotations', with_text=True),\n",
            "            dict(\n",
            "                meta_keys=(\n",
            "                    'img_path',\n",
            "                    'ori_shape',\n",
            "                    'img_shape',\n",
            "                    'valid_ratio',\n",
            "                ),\n",
            "                type='PackTextRecogInputs'),\n",
            "        ],\n",
            "        type='ConcatDataset'),\n",
            "    drop_last=False,\n",
            "    num_workers=4,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(_scope_='mmocr', shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(\n",
            "    _scope_='mmocr',\n",
            "    dataset_prefixes=[\n",
            "        'CUTE80',\n",
            "        'IIIT5K',\n",
            "        'SVT',\n",
            "        'SVTP',\n",
            "        'IC13',\n",
            "        'IC15',\n",
            "    ],\n",
            "    metrics=[\n",
            "        dict(\n",
            "            mode=[\n",
            "                'exact',\n",
            "                'ignore_case',\n",
            "                'ignore_case_symbol',\n",
            "            ],\n",
            "            type='WordMetric'),\n",
            "        dict(type='CharMetric'),\n",
            "    ],\n",
            "    type='MultiDatasetsEvaluator')\n",
            "vis_backends = [\n",
            "    dict(_scope_='mmocr', type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    _scope_='mmocr',\n",
            "    name=\n",
            "    'time.struct_time(tm_year=2025, tm_mon=7, tm_mday=10, tm_hour=13, tm_min=41, tm_sec=58, tm_wday=3, tm_yday=191, tm_isdst=0)',\n",
            "    type='TextRecogLocalVisualizer',\n",
            "    vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = 'work_dirs/CEGD-R_evaluation_textrecog'\n",
            "\n",
            "07/10 13:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "07/10 13:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) VisualizationHook                  \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/models/textrecog/module_losses/ce_module_loss.py:101: UserWarning: padding does not exist in the dictionary\n",
            "  warnings.warn(\n",
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmocr/models/textrecog/postprocessors/base.py:60: UserWarning: padding does not exist in the dictionary\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loads checkpoint by local backend from path: ckpt/pretrained_mmocr/abinet-vision_20e_st-an_mj_20220915_152445-85cfb03d.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
            "\n",
            "07/10 13:41:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from ckpt/pretrained_mmocr/abinet-vision_20e_st-an_mj_20220915_152445-85cfb03d.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bonting/micromamba/envs/bonting-id/lib/python3.11/site-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, map_location=map_location)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "07/10 13:41:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [100/641]    eta: 0:00:02  time: 0.0034  data_time: 0.0003  memory: 205  \n",
            "07/10 13:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [200/641]    eta: 0:00:01  time: 0.0035  data_time: 0.0003  memory: 205  \n",
            "07/10 13:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [300/641]    eta: 0:00:01  time: 0.0035  data_time: 0.0003  memory: 205  \n",
            "07/10 13:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [400/641]    eta: 0:00:00  time: 0.0034  data_time: 0.0003  memory: 205  \n",
            "07/10 13:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [500/641]    eta: 0:00:00  time: 0.0034  data_time: 0.0003  memory: 205  \n",
            "07/10 13:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [600/641]    eta: 0:00:00  time: 0.0034  data_time: 0.0003  memory: 205  \n",
            "07/10 13:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [641/641]    recog/word_acc: 0.0047  recog/word_acc_ignore_case: 0.0047  recog/word_acc_ignore_case_symbol: 0.0047  recog/char_recall: 0.0854  recog/char_precision: 0.1020  data_time: 0.0004  time: 0.0036\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'recog/word_acc': 0.0047,\n",
              " 'recog/word_acc_ignore_case': 0.0047,\n",
              " 'recog/word_acc_ignore_case_symbol': 0.0047,\n",
              " 'recog/char_recall': 0.0854,\n",
              " 'recog/char_precision': 0.102}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mmengine.runner import Runner\n",
        "import time\n",
        "from mmengine import Config\n",
        "\n",
        "%cd ~/bonting-identification\n",
        "cfg = Config.fromfile('mmocr_configs/CEGD-R_evaluation_textrecog.py')\n",
        "\n",
        "# The location of pretrained weight\n",
        "cfg['load_from'] = 'https://download.openmmlab.com/mmocr/textrecog/abinet/abinet-vision_20e_st-an_mj/abinet-vision_20e_st-an_mj_20220915_152445-85cfb03d.pth'\n",
        "\n",
        "# Optionally, give visualizer a unique name to avoid dupliate instance being\n",
        "# created in multiple runs\n",
        "cfg.visualizer.name = f'{time.localtime()}'\n",
        "\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXmgGRcjOba2"
      },
      "source": [
        "It's also possible to evaluate with a stronger and more generalized pretrained weight, which were trained on larger datasets and achieved quite competitve acadmical performance, though it may not defeat the previous checkpoint overfitted to the toy dataset. ([readme](https://mmocr.readthedocs.io/en/dev-1.x/textrecog_models.html#sar))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WctaeVsYR4W_"
      },
      "source": [
        "### SVTP Dataset\n",
        "\n",
        "SVTP dataset is one of the six commonly used academic test sets that systematically reflects a text recognizer's performance. Now we will evaluate SAR on this dataset, and we are going to use [Dataset Preparer](https://mmocr.readthedocs.io/en/dev-1.x/user_guides/data_prepare/dataset_preparer.html) to get it prepared first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VEW3PQrFZ0g"
      },
      "outputs": [],
      "source": [
        "!python tools/dataset_converters/prepare_dataset.py svtp --task textrecog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taW5YraiBVNx"
      },
      "source": [
        "SVTP is now available in `data/svtp`, and the dataset config is available at `configs/textrecog/_base_/datasets/svtp.py`. Now we first point the `test_dataloader` to SVTP, then perform testing with the overfitted checkpoint. As this checkpoint is just overfitted to such a small dataset, it's not surprising that it performs well on the toy dataset and bad on SVTP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0MHNwybo0iI"
      },
      "outputs": [],
      "source": [
        "from mmengine import Config\n",
        "\n",
        "svtp_cfg = Config.fromfile('configs/textrecog/_base_/datasets/svtp.py')\n",
        "svtp_cfg.svtp_textrecog_test.pipeline = cfg.test_pipeline\n",
        "cfg.test_dataloader.dataset = svtp_cfg.svtp_textrecog_test\n",
        "\n",
        "# The location of pretrained weight\n",
        "cfg['load_from'] = 'work_dirs/sar_resnet31_parallel-decoder_5e_toy/epoch_100.pth'\n",
        "\n",
        "# Optionally, give visualizer a unique name to avoid dupliate instance being\n",
        "# created in multiple runs\n",
        "cfg.visualizer.name = f'{time.localtime()}'\n",
        "\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLCHDGCbD3HG"
      },
      "source": [
        "Let's evaluate the pretrained one for comparision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S50EImkCvc7"
      },
      "outputs": [],
      "source": [
        "# The location of pretrained weight\n",
        "cfg['load_from'] = 'https://download.openmmlab.com/mmocr/textrecog/sar/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real/sar_resnet31_parallel-decoder_5e_st-sub_mj-sub_sa_real_20220915_171910-04eb4e75.pth'\n",
        "cfg.visualizer.name = f'{time.localtime()}'\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
