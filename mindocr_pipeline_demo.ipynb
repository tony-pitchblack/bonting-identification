{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# MindOCR Pipeline Demo\n",
        "\n",
        "This notebook demonstrates the MindOCR text detection and recognition pipeline used in `predict_system.py` on a single test image.\n",
        "\n",
        "## Pipeline Components:\n",
        "- **TextDetector**: Detects text regions in the image\n",
        "- **TextRecognizer**: Recognizes text content in detected regions  \n",
        "- **TextSystem**: Combines detection and recognition into a unified pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MindOCR root: /home/bonting/bonting-identification/mindocr\n",
            "Test image: data/HF_dataset/samples/ear-tags/sample_cow_ear_tag.png\n",
            "Image exists: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from types import SimpleNamespace\n",
        "from pathlib import Path\n",
        "\n",
        "# Add MindOCR paths\n",
        "mindocr_root = os.path.abspath(\"mindocr\")\n",
        "mindocr_tools_path = os.path.join(mindocr_root, \"tools/infer/text\")\n",
        "sys.path.insert(0, mindocr_root)\n",
        "sys.path.insert(0, mindocr_tools_path)\n",
        "\n",
        "# Import MindOCR modules\n",
        "import mindspore as ms\n",
        "from predict_system import TextSystem\n",
        "from config import parse_args\n",
        "\n",
        "# Set MindSpore context\n",
        "ms.set_context(mode=0)  # Graph mode\n",
        "\n",
        "# Test image path\n",
        "TEST_IMG_PATH = 'data/HF_dataset/samples/ear-tags/sample_cow_ear_tag.png'\n",
        "\n",
        "print(f\"MindOCR root: {mindocr_root}\")\n",
        "print(f\"Test image: {TEST_IMG_PATH}\")\n",
        "print(f\"Image exists: {os.path.exists(TEST_IMG_PATH)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration created successfully!\n",
            "Detection algorithm: DB++\n",
            "Recognition algorithm: CRNN\n",
            "Output directory: ./mindocr_output\n"
          ]
        }
      ],
      "source": [
        "# Create configuration arguments similar to run_mindocr_demo.sh\n",
        "args = SimpleNamespace(\n",
        "    # Detection settings\n",
        "    det_algorithm=\"DB++\",\n",
        "    det_model_dir=None,  # Use pretrained\n",
        "    det_limit_side_len=736,\n",
        "    det_limit_type=\"min\",\n",
        "    det_thresh=0.3,\n",
        "    det_box_thresh=0.6,\n",
        "    det_unclip_ratio=1.5,\n",
        "    det_use_dilation=False,\n",
        "    det_score_mode=\"slow\",\n",
        "    det_box_type=\"quad\",\n",
        "    det_amp_level=\"O0\",\n",
        "    det_batch_mode=False,\n",
        "    det_batch_num=8,\n",
        "    \n",
        "    # Recognition settings\n",
        "    rec_algorithm=\"CRNN\",\n",
        "    rec_model_dir=None,  # Use pretrained\n",
        "    rec_image_shape=\"3, 32, 320\",\n",
        "    rec_batch_mode=False,\n",
        "    rec_batch_num=8,\n",
        "    rec_amp_level=\"O0\",\n",
        "    rec_char_dict_path=None,  # Will be set automatically based on algorithm\n",
        "    \n",
        "    # Classification settings (disabled)\n",
        "    cls_algorithm=None,\n",
        "    cls_model_dir=None,\n",
        "    cls_batch_num=6,\n",
        "    cls_amp_level=\"O0\",\n",
        "    \n",
        "    # System settings\n",
        "    mode=0,  # Graph mode\n",
        "    drop_score=0.5,\n",
        "    warmup=False,\n",
        "    visualize_output=True,\n",
        "    save_crop_res=False,\n",
        "    save_cls_result=False,\n",
        "    \n",
        "    # Output directories\n",
        "    draw_img_save_dir=\"./mindocr_output\",\n",
        "    crop_res_save_dir=\"./mindocr_crops\",\n",
        "    vis_font_path=None,\n",
        "    \n",
        "    # Input (will be set per image)\n",
        "    image_dir=TEST_IMG_PATH\n",
        ")\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(args.draw_img_save_dir, exist_ok=True)\n",
        "\n",
        "print(\"Configuration created successfully!\")\n",
        "print(f\"Detection algorithm: {args.det_algorithm}\")\n",
        "print(f\"Recognition algorithm: {args.rec_algorithm}\")\n",
        "print(f\"Output directory: {args.draw_img_save_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing MindOCR TextSystem...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`rec_image_shape` [' 32', ' 320'] dose not meet the network input requirement or is not optimal, which should be [32, None] under batch mode = False\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'types.SimpleNamespace' object has no attribute 'rec_char_dict_path'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the TextSystem (combines detection and recognition)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitializing MindOCR TextSystem...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m text_system = \u001b[43mTextSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTextSystem initialized successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load and display the test image\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/bonting-identification/mindocr/tools/infer/text/predict_system.py:237\u001b[39m, in \u001b[36mTextSystem.__init__\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args):\n\u001b[32m    236\u001b[39m     \u001b[38;5;28mself\u001b[39m.text_detect = TextDetector(args)\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28mself\u001b[39m.text_recognize = \u001b[43mTextRecognizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m.cls_algorithm = args.cls_algorithm\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cls_algorithm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/bonting-identification/mindocr/tools/infer/text/predict_rec.py:106\u001b[39m, in \u001b[36mTextRecognizer.__init__\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.preprocess = Preprocessor(\n\u001b[32m     96\u001b[39m     task=\u001b[33m\"\u001b[39m\u001b[33mrec\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     97\u001b[39m     algo=args.rec_algorithm,\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m     rec_batch_num=\u001b[38;5;28mself\u001b[39m.batch_num,\n\u001b[32m    101\u001b[39m )\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# TODO: try GeneratorDataset to wrap preprocess transform on batch for possible speed-up.\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m#  if use_ms_dataset: ds = ms.dataset.GeneratorDataset(wrap_preprocess, ) in run_batchwise\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[38;5;28mself\u001b[39m.postprocess = Postprocessor(\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     task=\u001b[33m\"\u001b[39m\u001b[33mrec\u001b[39m\u001b[33m\"\u001b[39m, algo=args.rec_algorithm, rec_char_dict_path=\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrec_char_dict_path\u001b[49m\n\u001b[32m    107\u001b[39m )\n\u001b[32m    109\u001b[39m \u001b[38;5;28mself\u001b[39m.vis_dir = args.draw_img_save_dir\n\u001b[32m    110\u001b[39m os.makedirs(\u001b[38;5;28mself\u001b[39m.vis_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'types.SimpleNamespace' object has no attribute 'rec_char_dict_path'"
          ]
        }
      ],
      "source": [
        "# Initialize the TextSystem (combines detection and recognition)\n",
        "print(\"Initializing MindOCR TextSystem...\")\n",
        "text_system = TextSystem(args)\n",
        "print(\"TextSystem initialized successfully!\")\n",
        "\n",
        "# Load and display the test image\n",
        "image = cv2.imread(TEST_IMG_PATH)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "print(f\"Image shape: {image_rgb.shape}\")\n",
        "print(f\"Image dtype: {image_rgb.dtype}\")\n",
        "\n",
        "# Display the original image\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_rgb)\n",
        "plt.title(f\"Original Test Image: {os.path.basename(TEST_IMG_PATH)}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run text detection only to visualize detected bounding boxes\n",
        "print(\"Running text detection...\")\n",
        "det_res, data = text_system.text_detect(TEST_IMG_PATH, do_visualize=False)\n",
        "polys = det_res[\"polys\"]\n",
        "scores = det_res[\"scores\"]\n",
        "\n",
        "print(f\"Detected {len(polys)} text regions\")\n",
        "print(f\"Detection scores: {scores}\")\n",
        "\n",
        "# Create visualization with detected bounding boxes\n",
        "def draw_boxes(image, boxes, scores=None, color=(0, 255, 0), thickness=2):\n",
        "    \"\"\"Draw bounding boxes on image\"\"\"\n",
        "    img_with_boxes = image.copy()\n",
        "    for i, box in enumerate(boxes):\n",
        "        # Convert to integer coordinates\n",
        "        pts = box.astype(np.int32)\n",
        "        cv2.polylines(img_with_boxes, [pts], True, color, thickness)\n",
        "        \n",
        "        # Add score text if available\n",
        "        if scores is not None:\n",
        "            score_text = f\"{scores[i]:.3f}\"\n",
        "            cv2.putText(img_with_boxes, score_text, \n",
        "                       (pts[0][0], pts[0][1] - 5), \n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
        "    return img_with_boxes\n",
        "\n",
        "# Draw detected boxes\n",
        "image_with_boxes = draw_boxes(image_rgb, polys, scores)\n",
        "\n",
        "# Display image with detected bounding boxes\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(image_with_boxes)\n",
        "plt.title(f\"Detected Text Regions ({len(polys)} boxes)\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# Print detection details\n",
        "for i, (poly, score) in enumerate(zip(polys, scores)):\n",
        "    print(f\"Box {i+1}: Score={score:.3f}, Points={poly.astype(int)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the complete pipeline (detection + recognition)\n",
        "print(\"Running complete OCR pipeline...\")\n",
        "boxes, text_scores, time_profile = text_system(TEST_IMG_PATH, do_visualize=False)\n",
        "\n",
        "print(f\"\\nPipeline completed!\")\n",
        "print(f\"Final results: {len(boxes)} text regions after filtering\")\n",
        "print(f\"Time profile: {time_profile}\")\n",
        "\n",
        "# Display recognized texts\n",
        "print(f\"\\nRecognized texts:\")\n",
        "for i, (text, score) in enumerate(text_scores):\n",
        "    print(f\"  {i+1}. '{text}' (confidence: {score:.3f})\")\n",
        "\n",
        "# Create enhanced visualization with both boxes and text\n",
        "def draw_boxes_with_text(image, boxes, text_scores, box_color=(0, 255, 0), text_color=(255, 0, 0)):\n",
        "    \"\"\"Draw bounding boxes with recognized text\"\"\"\n",
        "    img_result = image.copy()\n",
        "    \n",
        "    for i, (box, (text, score)) in enumerate(zip(boxes, text_scores)):\n",
        "        # Draw bounding box\n",
        "        pts = box.astype(np.int32)\n",
        "        cv2.polylines(img_result, [pts], True, box_color, 2)\n",
        "        \n",
        "        # Prepare text with confidence\n",
        "        display_text = f\"{text} ({score:.2f})\"\n",
        "        \n",
        "        # Find text position (above the box)\n",
        "        text_x = pts[0][0]\n",
        "        text_y = max(pts[0][1] - 10, 20)  # Ensure text is visible\n",
        "        \n",
        "        # Add background rectangle for better text visibility\n",
        "        (text_width, text_height), _ = cv2.getTextSize(\n",
        "            display_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1\n",
        "        )\n",
        "        cv2.rectangle(img_result, \n",
        "                     (text_x, text_y - text_height - 5),\n",
        "                     (text_x + text_width, text_y + 5),\n",
        "                     (255, 255, 255), -1)\n",
        "        \n",
        "        # Add text\n",
        "        cv2.putText(img_result, display_text, \n",
        "                   (text_x, text_y), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, text_color, 1)\n",
        "    \n",
        "    return img_result\n",
        "\n",
        "# Create final visualization\n",
        "final_image = draw_boxes_with_text(image_rgb, boxes, text_scores)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "plt.imshow(final_image)\n",
        "plt.title(f\"Complete OCR Results: {len(text_scores)} recognized texts\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance analysis and summary\n",
        "print(\"=\" * 60)\n",
        "print(\"MINDOCR PIPELINE SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nInput Image: {TEST_IMG_PATH}\")\n",
        "print(f\"Image Size: {image_rgb.shape[1]}x{image_rgb.shape[0]} pixels\")\n",
        "\n",
        "print(f\"\\nAlgorithms Used:\")\n",
        "print(f\"  - Detection: {args.det_algorithm}\")\n",
        "print(f\"  - Recognition: {args.rec_algorithm}\")\n",
        "print(f\"  - Classification: {'Disabled' if args.cls_algorithm is None else args.cls_algorithm}\")\n",
        "\n",
        "print(f\"\\nDetection Results:\")\n",
        "print(f\"  - Total detected regions: {len(polys)}\")\n",
        "print(f\"  - After confidence filtering (>{args.drop_score}): {len(boxes)}\")\n",
        "\n",
        "print(f\"\\nRecognition Results:\")\n",
        "for i, (text, score) in enumerate(text_scores):\n",
        "    print(f\"  {i+1:2d}. '{text}' (confidence: {score:.3f})\")\n",
        "\n",
        "if time_profile:\n",
        "    print(f\"\\nPerformance Metrics:\")\n",
        "    for stage, time_ms in time_profile.items():\n",
        "        print(f\"  - {stage.capitalize()}: {time_ms:.3f}s\")\n",
        "    \n",
        "    total_time = time_profile.get('all', sum(time_profile.values()))\n",
        "    print(f\"  - Total: {total_time:.3f}s\")\n",
        "\n",
        "print(f\"\\nOutput saved to: {args.draw_img_save_dir}\")\n",
        "print(\"\\nPipeline demonstration completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## How to Run This Notebook\n",
        "\n",
        "1. **Environment Setup**: Make sure you have MindOCR installed and the micromamba environment activated:\n",
        "   ```bash\n",
        "   eval \"$(micromamba shell hook --shell bash)\"\n",
        "   micromamba activate bonting-id\n",
        "   ```\n",
        "\n",
        "2. **Test Image**: Ensure the test image exists at `data/HF_dataset/samples/ear-tags/sample_cow_ear_tag.png`\n",
        "\n",
        "3. **Run Cells**: Execute the cells in order. The notebook will:\n",
        "   - Initialize the MindOCR TextSystem with DB++ detection and CRNN recognition\n",
        "   - Load and display the test image\n",
        "   - Show detected bounding boxes\n",
        "   - Run the complete OCR pipeline\n",
        "   - Display results with both boxes and recognized text\n",
        "   - Provide performance metrics and summary\n",
        "\n",
        "## Key Features Demonstrated\n",
        "\n",
        "- **Text Detection**: Uses DB++ algorithm to detect text regions\n",
        "- **Text Recognition**: Uses CRNN algorithm to recognize text content  \n",
        "- **Pipeline Integration**: Shows how detection and recognition work together\n",
        "- **Visualization**: Displays bounding boxes and recognized text overlays\n",
        "- **Performance Metrics**: Reports timing for each pipeline stage\n",
        "\n",
        "This notebook replicates the functionality of `predict_system.py` in an interactive format, making it easy to understand how the MindOCR pipeline works step by step.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
